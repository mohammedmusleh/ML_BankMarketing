{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset: https://www.kaggle.com/janiobachmann/bank-marketing-dataset/activity\n",
    "#Dataset Link: https://archive.ics.uci.edu/ml/datasets/Bank+Marketing\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data =  (11162, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2343</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>45</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>1467</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>1270</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>1389</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2476</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>184</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>673</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         job  marital  education default  balance housing loan  contact  \\\n",
       "0   59      admin.  married  secondary      no     2343     yes   no  unknown   \n",
       "1   56      admin.  married  secondary      no       45      no   no  unknown   \n",
       "2   41  technician  married  secondary      no     1270     yes   no  unknown   \n",
       "3   55    services  married  secondary      no     2476     yes   no  unknown   \n",
       "4   54      admin.  married   tertiary      no      184      no   no  unknown   \n",
       "\n",
       "   day month  duration  campaign  pdays  previous poutcome deposit  \n",
       "0    5   may      1042         1     -1         0  unknown     yes  \n",
       "1    5   may      1467         1     -1         0  unknown     yes  \n",
       "2    5   may      1389         1     -1         0  unknown     yes  \n",
       "3    5   may       579         1     -1         0  unknown     yes  \n",
       "4    5   may       673         2     -1         0  unknown     yes  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('bank.csv')\n",
    "print('Shape of the data = ',data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'sorted'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-d6f6cf68ddc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ggplot'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m37\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'balance'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0my_pdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0my_cdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'sorted'"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "np.random.seed(37)\n",
    "x = data['balance'].values\n",
    "y_pdf = norm.pdf(x)\n",
    "y_cdf = norm.cdf(x)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "ax = [ax, ax.twinx()]\n",
    "\n",
    "_ = ax[0].plot(x, y_pdf, label='pdf', color='r')\n",
    "_ = ax[1].plot(x, y_cdf, label='cdf', color='b')\n",
    "\n",
    "_ = ax[0].tick_params(axis='y', labelcolor='r')\n",
    "_ = ax[1].tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "_ = ax[0].set_ylabel('pdf', color='r')\n",
    "_ = ax[1].set_ylabel('cdf', color='b')\n",
    "\n",
    "_ = ax[0].set_title('PDF and CDF of standard normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15a7e5109c8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEJCAYAAACE39xMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXRUZZ4+8OdW3aSyh6SKJAZCgAQYFllC2NLIImm6Z0Y4jC3i1qKRcSAiAtIIKouNGRhPs7SAwhE6KNJ24DeCIiNqBESJtEEIytKYQPCEJiQkFcieWu77+6NImVqSyl5V4fmck1N1733r1rdeiidv3rp1rySEECAiIq+ncncBRETUPhjoRERdBAOdiKiLYKATEXURDHQioi6CgU5E1EUw0MljXb16FZIk4ZtvvnF3Ke2ivLwc//Ef/4GQkBBIkoSrV686tDl27BgkScK1a9fa9Fy7du2CLMtt2gd5Hwa6l3vqqacgSRIkSYIsy4iNjcXcuXNRWlpqbVO/XZIk+Pn5ISYmBtOnT8e+ffsc9te7d2+b9vU/N27c6MyX1SLV1dV4/fXXMXToUAQEBCA8PBxjxozB5s2bUV1dDQBYvXq19bWo1Wp069YNI0eOxNKlS1FQUGCzv127djntg7lz57apzrfffhvffvstTpw4gcLCQsTExLRpf0T2+Cu8C7jvvvuwd+9emEwmfP/995gzZw4KCgpw6NAha5stW7bgd7/7HYxGI65du4aDBw/i97//Pfbt24e//e1vUKl++d3+0ksvYeHChTbPERER0WmvpyXKy8sxceJEXL9+HX/84x8xZswYhIaG4tSpU3jzzTcRExODGTNmALD8svr2228hhEB5eTnOnDmDjRs3Ytu2bTh8+DCSkpKs+1Wr1Q6j5ICAgDbVmpubi8GDB+Pee+9t036IGiXIq82ePVtMmTLFZt3rr78uVCqVqK6uFkIIAUDs3r3b4bEHDx4UAMS7775rXRcbGyvWrFnT7OdXFEXMmTNH9O3bV/j5+Yk+ffqI5cuXi9raWmubVatWibi4OHHgwAExYMAAERAQICZNmiTy8vJs9pWRkSHi4uKERqMR48aNEx999JEAIL7++utGn3/+/PnCz89PXLlyxWltZWVlNjXYMxgMYuzYsSI+Pl6YzWYhhBDp6elCrVY3uw/q9/PSSy+J6Oho4ePjIwYOHCj27Nlj3R4bGysAWH8mTpzodD9Hjx4VAMTHH38sRo0aJTQajRg0aJD4/PPPbV6Xqz63fw16vV48/vjjIiYmRvj5+Yn+/fuLP/3pT0JRFGub+vfS9u3bRa9evURwcLCYPn26KC4utqnxiy++EOPHjxf+/v4iJCRETJgwwebf8oMPPhDDhg0TGo1GxMbGikWLFonKysoW9Se1DqdcuiB/f38oigKTydRkuwceeACDBw/G3r17W/1cQghERkbir3/9Ky5evIhNmzYhPT0d//3f/23TrrCwEG+//Tb27NmDrKws3Lp1CykpKdbtZ86cwSOPPIKZM2fi7NmzWLJkCV544YUmn1tRFPz1r3/F448/jj59+jhslyQJ3bp1a3IfPj4+ePHFF5GXl4fTp0+34JXbevnll/HOO+9g06ZNOHfuHJ544gk88cQT+PLLLwEA2dnZePjhh3HfffehsLAQH374YZP7W7x4MVauXIkzZ85g7NixmD59Ov75z38CaH6fN1RXV4d7770XBw4cwIULF7BixQqsWrUKu3btsmmXnZ2No0eP4tChQzh8+DBycnKwZMkS6/bMzEz85je/wciRI/Htt9/i73//O5588kkYjUYAlumqefPm4cUXX8SFCxfw3nvvITMzs83TVdRM7v6NQm1jP0I/f/686Nu3rxgzZox1HRoZoQshxKxZs8TAgQOty7GxscLX11cEBgZaf2bPnt2imjZs2CDi4+Oty6tWrRJqtdpmpPfBBx8ISZJETU2NEEKIxx9/XIwbN85mP5s3b25yhF5UVCQAiPXr17usqbERuhBCXLx4UQAQGRkZQgjL6BaATR8EBgaKS5cuOX18VVWV8PX1FVu3brVZP2PGDDF58mTrsrO/puzVj9B37NhhXWc0GkWvXr3EK6+80ujj7Pu8OX9lLFiwQCQnJ9vUp9PpbEb6a9euFVFRUdbl8ePHi3//939vdJ+xsbHi7bfftln31VdfCQBCr9c3WQ+1HefQu4Bjx44hKCgIZrMZdXV1mDJlCrZv396sxwohIEmSzbrnnnsOqamp1uXg4OAm9/HOO+9gx44duHr1KqqqqmAymaAoik2b6OhodO/e3brco0cPCCFQXFyMXr164cKFC5gyZYrNY8aPH++ydgAO9beUs/2o1Wrk5OTYtIuNjXX6+Ly8PBgMBkyYMMFm/cSJE7F27dpW1TRu3DjrfVmWMXr0aFy4cMG6rjl93pCiKHjjjTfwt7/9DdeuXUNtbS2MRqPDaxo4cCA0Go11uUePHigqKrIuf//991i3bp3T57h58yZ+/vlnLF682GZUX9+/eXl5GDVqVDN7gFqDgd4FjBkzBu+++y5kWcY999xj8x/SlXPnziEuLs5mXXh4OOLj45v1+H379uG5557DunXrMHHiRISEhGDfvn145ZVXbNr5+vraLNeHZ30IOfvF4kr37t0RFhaG8+fPt+hx9s6dOwcADv3Q3D6oZ19/a15TY0SDk6I2t88bWr9+PdauXYsNGzYgISEBwcHB2Lhxo80H54Dzfydhd0LWxl5T/b/ln//8Z0yePNlhe8+ePZt+kdRmnEPvAvz9/REfH4/evXu3KMwPHjyICxcuYNasWa1+7uPHj2PEiBFYvHgxRo4ciX79+jk9vtqVwYMH48SJEzbr7JftqVQqPPbYY9izZw/y8/MdtgshcPv27Sb3YTQasWHDBvTv3x/Dhw9vcd2AJfg1Gg2++uorm/XHjx/H4MGDW7XPkydPWu+bTCZkZ2dj4MCB1v22tM+PHz+O3/72t3jmmWcwYsQIxMfHIzc3t8V1jRw5Ep999pnTbZGRkYiJicGlS5cQHx/v8OPn59fi56OW4Qj9LnH79m3cuHHD5rDFjRs34pFHHsGjjz7a6v0OGDAAO3fuxEcffYQhQ4bgk08+cfmBnzOLFi3CqFGj8Morr2D27Nk4f/481q9f7/JxaWlpOH78OMaOHYs1a9ZgzJgxCAkJQU5ODjZu3IjFixdbD1s0m83W4+lv375tPWzxH//4Bz777DObQzdbIiAgAAsWLMCKFSvQvXt3DB8+HPv27cNHH32EL774olX7XLduHaKiotCnTx9s2LABRUVFmDdvHoDW9fmAAQOwe/duHD16FD169MB7772Hv//97wgLC2tRXStWrMC//uu/YuHChUhJSYFGo8G3336LcePGYcCAAUhLS8MzzzyDbt26YcaMGfDx8cHFixfx6aefNnsakNrAXZP31D6a80EbGhwu5+vrK3r06CGmTZsm9u7d69C2pYctGgwG8eyzz4qwsDARHBwsHn30UeuHmfWcfSD59ddfCwAiPz/fuu6DDz4Qffv2Fb6+vmL06NHiwIEDLg9bFEKIyspKsXr1ajF48GDh5+cnunXrJkaPHi22bNliPXRz1apV1j6QJEmEhISIESNGiD/84Q+ioKDAZn8dcdiiEC37UPSjjz4SCQkJwtfXVwwcOFAcPnzY5rlc9bn9a7h165aYOXOmCA4OFuHh4SI1NVW8+uqrIjY2tsn6du/eLexj4vDhw2Ls2LHCz89PhISEiEmTJonLly9bt+/fv1+MHTtW+Pv7i+DgYDFs2DDx2muvue5EajNJCF6xiIioK+AcOhFRF8FAJyLqIhjoRERdBAOdiKiLYKATEXURbj0O/fr16+58+kbpdDqUlJS4uwyPwj5xxD5xxD5x1N59Eh0d3eg2jtCJiLoIBjoRURfBQCci6iIY6EREXQQDnYioi3B5lMtbb72F06dPIzQ01OnZ74QQSE9Px5kzZ6DRaJCamoq+fft2SLFERNQ4lyP0SZMm4eWXX250+5kzZ3Djxg28+eabePbZZ7Fjx452LZCIiJrH5Qh90KBBKC4ubnT7qVOnMGHCBEiShP79+6OqqgplZWUtPs8ydW1CAIrS8EeyWwaEkFBXB1RVqRqs++VWCMnJesmmTcN9/fI42zqc3drftyxLDtsa3oaESCgv92vWPp2d07R+/815XPP3+cu+6/vC2XZnj2/qvKvN6RsACAxUobIysNXP2R41uFpu7baW1NNwe0CAGlVVtpdx/PWvazF8uLHxnbdSm79YpNfrodPprMtarRZ6vd5poGdmZiIzMxOA5QT+DR/nSWRZ9tjaWsNkAm7dAurqLPdNJsBstvyYTBKMRqCmBqiqAqqrgaoqCVVVluWaGqCuToLZrEJdXSSqqy37Mpkk677q92cwAGVlQGWlJZhray3PaTQCZnP7XIrN84S7uwAPFOruAjxQMCTpl98AcXH+SE5u/BqwrdXmQHd2OvXGrjmYnJyM5ORk67KnfqPMG77tZjAAxcVq3LihQlGRGkVFlvs3blju37ypQmWlhIoKFcrL2/bZt0ol4OMDyLIEPz+B0FABX18FajWgVguo1YAsW9r07q0gKEjA11dAoxHw9bVsk2VLW5UKDX4EJAlQq39ZlmUgOFhYt9W3tdy3rKtf/8utY1u1GgAszwdY1tWrv29/63ybs/e35TY8PAxlZWWt2GfDvYlGt7V2n/X3G/aXs/oda2lZ2/raG27TarUoLS3tsOdsetn+2qet22971gc0nietjZimvina5kDXarU2xZaWlnK6pZ3V1Ej47jtfnD7tg3/+U43z533w448+Dn/i+fgIREaaERmpoG9fE4KCBIKDFYSFKQgNtQSsLNcHsCVgLbeAv7+Av7+CgABh8+Pvb2njDb/kOptOJ1BSYnJ3GR4lPBxQFF4zx13aHOiJiYk4fPgwfvWrXyE3NxcBAQEM9DZQFOCHH3xw6ZKMy5dlnDrlizNnfGEwSJAkgYgIBffcY8b8+ZXo1cuMyEgzoqLMiIqyBHcrL4tJRF2Ay0DftGkTLly4gIqKCsydOxcPP/wwTCbLqGTq1KkYMWIETp8+jQULFsDX1xepqakdXnRXU1cHfPutBv/3f374/HM/3LypBmCZqhgyxIhnnqnC+PF1SEw0ICiIox8ics5loC9cuLDJ7ZIkYc6cOe1W0N3kn/9UYceOIOzdG4Bbt1QICFBw//11+O1vazFsmAG9epkhu/V8mETkTRgXbnDlihrvvx+IXbsCoSjAlCm1eOSRatx3Xx38/NxdHRF5KwZ6J6qulvA//xOMHTuCIEkCDz1Ugz/8oQI9epjdXRoRdQEM9E6SmanBqlWhuHpVxqOPVuHFFytwzz3tfxwqEd29GOgd7Pp1FV55JRSff+6P+HgjPvigBBMmGNxdFhF1QQz0DnT5shqPPaZFaakKr7xSjjlzKuHr6+6qiKirYqB3kPPnZTz0kA6SBHz4YSmGDm3/8zYQETXEQO8At29LeOGFMPj5CXz8cQliYvihJxF1PAZ6OxMCePHFbsjNlbFjh55hTkSdhl8Ub2eHDvnh00/98dJLFfj1r+vcXQ4R3UUY6O2ovFzCypWhGDzYiGefrXR3OUR0l+GUSztaurQbiotV+Mtf9PzKPhF1Oo7Q28nnn2tw8KA/Fi2q7JArkRARucJAbwcGA7ByZSgGDjTi+ecr3F0OEd2lODHQDj74IAAFBTLef7+UXxwiIrfhCL2NzGZgy5YgjB5dh0mTeFQLEbkPA72Nvv5ag+vXZcyZU+X0eoJERJ2Fgd5Ge/f6o1s3BcnJte4uhYjucgz0Nrh9W8Lhw/548MFqaDTuroaI7nYM9DY4fNgPdXUSHnywxt2lEBEx0Nvio4/8ERtr4nHnROQRGOitVFKiwjffaDB9eg0/DCUij8BAb6XPPvOD2Sxh2jROtxCRZ2Cgt9LRoxrcc48ZgwaZ3F0KEREABnqrGAyW48/vv7+W0y1E5DEY6K1w6pQvKitVmDyZ3wwlIs/BQG+FY8c0kGWB8eMZ6ETkORjorXDsmB9GjTIgOFi4uxQiIisGegtVVkq4cEHGuHEGd5dCRGSDgd5CZ8/6QAgJI0Yw0InIszDQW+jMGcsJz4cPZ6ATkWdhoLfQmTM+6NPHhPBwzp8TkWdp1hWLcnJykJ6eDkVRMGXKFMyYMcNme0lJCbZu3YqqqiooioLHHnsMCQkJHVKwOwlhGaH/6lc8uoWIPI/LQFcUBTt37sSrr74KrVaL5cuXIzExET179rS2+d///V+MGzcOU6dOxbVr17B27douGejXr6tQVKTGyJGcbiEiz+NyyiUvLw9RUVGIjIyELMtISkpCdna2TRtJklBdXQ0AqK6uRlhYWMdU62b18+cjRvDsikTkeVyO0PV6PbRarXVZq9UiNzfXps3MmTPx+uuv4/Dhw6irq8OKFSuc7iszMxOZmZkAgHXr1kGn07Wl9g4jy7LT2n76SQ1fX4H77gu96y4G3Vif3M3YJ47YJ446s09cBroQjh/+SXYnMDlx4gQmTZqEadOm4aeffsLmzZuxfv16qFS2fwAkJycjOTnZulxSUtLaujuUTqdzWtvJk1oMHCihvNwz6+5IjfXJ3Yx94oh94qi9+yQ6OrrRbS6nXLRaLUpLS63LpaWlDlMqR44cwbhx4wAA/fv3h9FoREVFRWvr9UiKAvz4ow+GDuV0CxF5JpeBHhcXh8LCQhQXF8NkMiErKwuJiYk2bXQ6Hc6dOwcAuHbtGoxGI0JCQjqmYje5elWN8nIVhg1joBORZ3I55aJWq5GSkoK0tDQoioLJkycjJiYGGRkZiIuLQ2JiIp588kls374dhw4dAgCkpqY6TMt4u/PnfQAAQ4Yw0InIMzXrOPSEhASHwxBnzZplvd+zZ0+sWbOmfSvzMFeuWLqqb19e0IKIPBO/KdpM+fkyoqLMCAzkN0SJyDMx0JspP19Gnz4cnROR52KgN1N+vpqBTkQejYHeDLdvSygtVXP+nIg8GgO9GfLzLR+I9uljdnMlRESNY6A3wy+BzhE6EXkuBnozXLkiQ5IEYmMZ6ETkuRjozZCfr0aPHmb4+bm7EiKixjHQmyE/X+YHokTk8RjoLghRfww6PxAlIs/GQHehrEyF27dV/ECUiDweA92F69ctXdSzJ0foROTZGOgu3LihBgBERjLQicizMdBdKCqqD3TFzZUQETWNge5CcbGli7p35widiDwbA92FGzfUCA8333UXhSYi78NAd6G4WMXpFiLyCgx0F4qK1PxAlIi8AgPdBUugc4RORJ6Pgd4Esxm4eVOFiAiO0InI8zHQm6DXq2A2S4iKYqATkedjoDehqMjSPRERnHIhIs/HQG8CvyVKRN6Egd6E0tL6LxVxhE5Eno+B3oSyMkv3hIUx0InI8zHQm1BWpoIsCwQFCXeXQkTkEgO9CWVlKnTrpkCS3F0JEZFrDPQmlJWpON1CRF6Dgd6EW7csI3QiIm/AQG8CR+hE5E3k5jTKyclBeno6FEXBlClTMGPGDIc2WVlZ2LdvHyRJQmxsLF544YV2L7azlZWpMHQoPxAlIu/gMtAVRcHOnTvx6quvQqvVYvny5UhMTETPnj2tbQoLC3HgwAGsWbMGQUFBuH37docW3Vlu3ZI4Qicir+FyyiUvLw9RUVGIjIyELMtISkpCdna2TZsvv/wSv/nNbxAUFAQACA0N7ZhqO1FNDVBbyzl0IvIeLkfoer0eWq3WuqzVapGbm2vT5vr16wCAFStWQFEUzJw5E8OHD3fYV2ZmJjIzMwEA69atg06na1PxHUWWZUiSpbaYmADodH5ursj9ZFn22H8vd2GfOGKfOOrMPnEZ6EI4ziFLdgdmK4qCwsJCrFq1Cnq9HitXrsT69esRGBho0y45ORnJycnW5ZKSktbW3aF0Oh2uXLkFIAI+PuUoKal1d0lup9PpPPbfy13YJ47YJ47au0+io6Mb3eZyykWr1aK0tNS6XFpairCwMJs24eHhGDVqFGRZRkREBKKjo1FYWNiGkt3v1i1L13DKhYi8hctAj4uLQ2FhIYqLi2EymZCVlYXExESbNqNHj8a5c+cAAOXl5SgsLERkZGTHVNxJysstXRMaykAnIu/gcspFrVYjJSUFaWlpUBQFkydPRkxMDDIyMhAXF4fExEQMGzYMZ8+exaJFi6BSqfDEE08gODi4M+rvMOXllmml4GAetkjkqYQQqK2thaIoDlPBnqKoqAh1dXUteowQAiqVCn5+fi16Xc06Dj0hIQEJCQk262bNmmW9L0kSZs+ejdmzZzf7iT1dZaVlhM5AJ/JctbW18PHxgSw3K8rcQpZlqNXqFj/OZDKhtrYW/v7+zX4MvynaiPoRelAQp1yIPJWiKB4d5m0hyzIUpWX5w0BvRGWlCn5+Ar6+7q6EiBrjqdMs7aWlr69r/mprB+XlEoKDOTonosbFxMTgX/7lX2A2mxEfH48///nP8Pf3t643mUyQZRkPPfQQ/vM//xMqlQpZWVlISUlBTEwMAMtRghkZGe1SDwO9ERUVKs6fE1GT/Pz88MUXXwAA5s+fj/feew//9V//ZbO+rKwMc+fORUVFBZYsWQLAcmTge++91+71cMqlEZWVHKETUfONHj0aV69edVjfvXt3vPHGG0hPT3f6Rc32xBF6I8rLOUIn8iYhK1fC58KFdt2ncdAglP/xjy7bmUwmHD16FJMmTXK6PTY2FkII6zdGv/vuO/z6178GADzwwAPtdnZaBnojKislRESY3V0GEXmw2tpaazCPGTMGjz76aKNtG47OO2rKhYHeiIoKCYGBHKETeYvmjKTbW8O58qb8/PPPUKlU0Ol0Dic3bE+cQ29ETY2EgAAGOhG1TUlJCZYtW4ann366ww+z5Ai9ETU1Evz9GehE1HL1UzH1hy3+7ne/w7PPPtvhz8tAd0IIoKZGxUAnoiY1Nn1SUFBgvS/LMkwmk3U5KSkJSUlJHVIPp1ycqL1z+nMGOhF5Ewa6E9XVllsGOhF5Ewa6E1VVltuAAH6xiIi8BwPdCY7QicgbMdCdqKmxHFrEQCcib8JAd6J+hO7nx0AnIu/Bwxad4JQLETVXcXExVq1ahbNnz8LX1xcxMTFYvXo1pk6diri4OBgMBgQGBmL27Nl4+OGHAQAZGRl4/fXXERUVBQAYOHAg3nzzzTbXwkB3goFORM0hhMAzzzyDmTNn4u233wYAnDt3DiUlJYiNjcXnn38OWZZx+fJlzJkzB0II6+U7p0+fjrS0tHath1MuTlRXcw6diFw7ceIEfHx88OSTT1rXDRkyBNHR0TbtYmNjsWrVKuzcubND6+EI3QmO0Im8z8qVIbhwwadd9zlokBF//GN5o9svXbqEe++9t1n7uvfee3H58mXr8scff4zvvvsOADBnzhzryL0tGOhO1Ac6T85FRO3F/uIWHTHlwkB3oqbGcssROpH3aGok3VH69++PQ4cONavtuXPnEB8f36H1cA7diepqCSqVgK+vuyshIk82fvx4GAwG7Nmzx7ouJycH165ds2lXUFCANWvWICUlpUPr4Qjdiaoqy+i8g09dTEReTpIk7NixA6tWrcLWrVuh0WjQs2dPvPbaa/j5558xdepU62GLKSkp7TJP3hQGuhPV1ZxuIaLmiYqKwvbt2x3W138Aan/6XACYNWtWh4Q7p1ycqKlhoBOR92GgO1FdzasVEZH3YaA7UV3NQxaJyPsw0J3glAuRd7A/truraenrY6A7UV0NaDRd+41C1BWoVCqHDxy7CpPJBJWqZRHdrKNccnJykJ6eDkVRMGXKFMyYMcNpu5MnT2LDhg1Yu3Yt4uLiWlSIJzEYAF9fBjqRp/Pz80NtbS3q6uogeehxxhqNBnV1dS16jBACKpUKfn5+LXqcy0BXFAU7d+7Eq6++Cq1Wi+XLlyMxMRE9e/a0aVdTU4NPP/0U/fr1a1EBnqiuTuKXioi8gCRJ8Pf3d3cZTdLpdCgpKemU53I5ns/Ly0NUVBQiIyMhyzKSkpKQnZ3t0C4jIwPTp0+Hj0/7nhzHHerqOEInIu/jcoSu1+uh1Wqty1qtFrm5uTZt8vPzUVJSgpEjR+LgwYON7iszMxOZmZkAgHXr1kGn07W27g5lNAKhoRqPrc8dZFlmf9hhnzhinzjqzD5xGejOPmVtOFelKAreffddpKamunyy5ORkJCcnW5c768+Qlqqruwdmcy1KSm67uxSP0Zl/NnoL9okj9omj9u4T+3OtN+Qy0LVaLUpLS63LpaWlCAsLsy7X1taioKAAr732GgDg1q1beOONN7B06VKv/WCUUy5E5I1cBnpcXBwKCwtRXFyM8PBwZGVlYcGCBdbtAQEBNlfhWL16NX7/+997bZgDlqNceNgiEXkbl4GuVquRkpKCtLQ0KIqCyZMnIyYmBhkZGYiLi0NiYmJn1NlphLAc5dIFPtslortMs45DT0hIQEJCgs26xs4Utnr16jYX5U5Go+WWUy5E5G34TVE7BoPlA19OuRCRt2Gg2zEYLLecciEib8NAt1M/QueUCxF5Gwa6HQY6EXkrBrqd+ikXnsuFiLwNA90OR+hE5K0Y6HYY6ETkrRjodozG+kB3cyFERC3EQLdTfx56jtCJyNsw0O1wyoWIvBUD3Q6nXIjIWzHQ7XDKhYi8FQPdDqdciMhbMdDtcMqFiLwVA90Op1yIyFsx0O1wyoWIvBUD3Q6nXIjIWzHQ7fxyci6O0InIuzDQ7dTVSVCrBdRqd1dCRNQyDHQ7RqPE6RYi8koMdDsGA6DRuLsKIqKWY6DbqauTGOhE5JUY6HY45UJE3oqBbsdg4CGLROSdGOh2DAYJGg0PWSQi78NAt2M0SvDxcXcVREQtx0C3YzKBgU5EXomBbsdkkiDL7q6CiKjlGOh2TCYw0InIKzHQ7ZjNDHQi8k7Niq6cnBykp6dDURRMmTIFM2bMsNn+ySef4Msvv4RarUZISAjmzZuH7t27d0jBHY1TLkTkrVyO0BVFwc6dO/Hyyy9j48aNOHHiBK5du2bTpnfv3li3bh3+9Kc/YezYsXj//fc7rOCOxhE6EXkrl4Gel5eHqKgoREZGQpZlJCUlITs726bNkCFDoLnzffl+/fpBr9d3TLWdgMV4QzEAAA20SURBVCN0IvJWLqNLr9dDq9Val7VaLXJzcxttf+TIEQwfPtzptszMTGRmZgIA1q1bB51O19J6O4EaPj6Sh9bmPrIss0/ssE8csU8cdWafuAx0IRy/NSlJktO2x48fx5UrV7B69Wqn25OTk5GcnGxdLikpaWaZnaeurjvUapVH1uZOOp2OfWKHfeKIfeKovfskOjq60W0up1y0Wi1KS0uty6WlpQgLC3No98MPP2D//v1YunQpfLz4mzmcciEib+Uy0OPi4lBYWIji4mKYTCZkZWUhMTHRpk1+fj7eeecdLF26FKGhoR1WbGfgh6JE5K1cRpdarUZKSgrS0tKgKAomT56MmJgYZGRkIC4uDomJiXj//fdRW1uLDRs2ALD8ifHSSy91ePEdwWjkCJ2IvFOzoishIQEJCQk262bNmmW9v2LFivatyo3MZvB6okTklfhNUTv86j8ReSsGuh2zmafPJSLvxEC3wxE6EXkrBrods5kfihKRd2Kg2+EInYi8FQO9ASE4Qici78VAb8BsttzKMi8STUTeh4HegMlkueUInYi8EQO9AZPJctIxfrGIiLwRA70BjtCJyJsx0Bswmy0jdLmuys2VEBG1HAO9AZPR8mGo71t/dnMlREQtx0BvwGRQAACa6z+7uRIiopZjoDdgrrMctyjD5OZKiIhajoHegPnOCJ2BTkTeiIHeAAOdiLwZA70BE6dciMiLMdAbMN85yoWBTkTeiIHeAKdciMibMdAbMBkajNAFT9BFRN6Fgd5Awzl06dYtN1dDRNQyDPQGGk65+Pz4o5urISJqGQZ6A+b6k3PBBE12tnuLISJqIQZ6A6aGI/Tvv3dzNURELcNAb6CqynK2Rb8AFXx++snN1RARtQwDvYFL+QFQwYy4YYFQFxZCdeOGu0siImo2BnoDF/KD0A+58PuP3wAA/A8dcnNFRETNx0Bv4GJ+CIbiB4ghQ2AcOBB+Bw+6uyQiomZjoN9RVSXhalEghuIHQK1GzbRp0GRnw/fkSXeXRkTULAz0O86d8wEAS6DLMqofeggAEDZvHmA0urM0IqJmYaDf8fXXGqgkBePxDSDLUHr0QNmGDVAXFyNy3DjIFy+6u0QioiY16/r2OTk5SE9Ph6IomDJlCmbMmGGz3Wg0YsuWLbhy5QqCg4OxcOFCREREdEjBHUEI4IsvNEjodhnhZWUwypZuqXn4YUCtRreFCxGRnAxzVBQqn3sOSlAQaqdNg/D3d3PlRES/cBnoiqJg586dePXVV6HVarF8+XIkJiaiZ8+e1jZHjhxBYGAgNm/ejBMnTmDPnj1YtGhRhxbeHqqqJFy/rsbOt31x7pwvdmAdAED06mVpIEmoeeghmKOj4ffZZwjasQOhK1ZYtt15fUKWUTt1Kky9e0PR6SBVV8McGwsRGAjh7w9zdDTMWi1EaChgNEIymQCDASIszPKbRAhAkiw/RERt4DLQ8/LyEBUVhcjISABAUlISsrOzbQL91KlTmDlzJgBg7Nix+Mtf/gIhBKQOCKn/98KP2HxgABSoICBBgWS5FSqb+zbboIIQtstmoUItfhlhv4g/4fExF3B9Tx50ERFASYl1myEpCYakJFQ++yx8Ll2C5tgxqCorEZCRAclkgt+nn0Jq4dkZFT8/SHV1liCXZQi1GtBoLAGvKFDCwhp9rFRVBVVFBZTw8E77RaBSqxFpNrfrPoWX/xJTyzIi2rlPOlUH9L9are68PvGS949apUKEotisq1i6FDUPPtjuz+Uy0PV6PbRarXVZq9UiNze30TZqtRoBAQGoqKhASEiITbvMzExkZmYCANatWwedTtfignv1C8ao6GuQIKCCGRIAlSQgSYBKUiz3AahUosE2AZUESJKwRLpkWd/dvwL3BNzG6AG3ET9rBERSKnSyDFmWndem0wHDhgEPPwwAMLz7riWAVSpAr4f0ww+Qbt6EiI6GdOkSoFYDNTVAVRWk6mrAdOe0vD4+QHk5RGCg5QPX8vJf9qNWA7W1lrBvhFRZCaVbt859Q0tS+55SWFj+fbzWnb+sWvqL3GN0VN2d1Sfe1O9O+iSoXz8EtiL/XHEZ6MJJx9mPvJvTBgCSk5ORnJxsXS5pMApurtHze2P0/BY/zKWbAHDnlLk6na5VtWHIkF/uDxjQLnV5ilb3SRfGPnHEPnHUaJ+0sp+io6Mb3ebyKBetVovS0lLrcmlpKcLspgMatjGbzaiurkZQUFCriiUiotZxGehxcXEoLCxEcXExTCYTsrKykJiYaNNm5MiROHbsGADg5MmTGDx4cIfMnxMRUeNcTrmo1WqkpKQgLS0NiqJg8uTJiImJQUZGBuLi4pCYmIj7778fW7ZswfPPP4+goCAsXLiwM2onIqIGJOFsAryTXL9+3V1P3STOAzpinzhinzhinzhq7z5p0xw6ERF5BwY6EVEXwUAnIuoiGOhERF2EWz8UJSKi9sMRuhPLli1zdwkeh33iiH3iiH3iqDP7hIFORNRFMNCJiLoIBroTDU8gRhbsE0fsE0fsE0ed2Sf8UJSIqIvgCJ2IqItgoBMRdRHNukj03cLVxbC9XUlJCbZu3Ypbt25BkiQkJyfj3/7t31BZWYmNGzfi5s2b6N69OxYtWoSgoCAIIZCeno4zZ85Ao9EgNTUVffv2BQAcO3YMH374IQDgwQcfxKRJkwAAV65cwdatW2EwGDBixAg8/fTTXnEqZUVRsGzZMoSHh2PZsmUoLi7Gpk2bUFlZiT59+uD555+HLMtNXhB9//79OHLkCFQqFZ5++mkMHz4cgHe+r6qqqrBt2zYUFBRAkiTMmzcP0dHRd/X75JNPPsGRI0cgSRJiYmKQmpqKW7duedb7RJAQQgiz2Szmz58vbty4IYxGo1iyZIkoKChwd1ntSq/Xi8uXLwshhKiurhYLFiwQBQUFYvfu3WL//v1CCCH2798vdu/eLYQQ4vvvvxdpaWlCURRx6dIlsXz5ciGEEBUVFeK5554TFRUVNveFEGLZsmXi0qVLQlEUkZaWJk6fPu2GV9pyBw8eFJs2bRJr164VQgixfv168c033wghhNi+fbv47LPPhBBCHD58WGzfvl0IIcQ333wjNmzYIIQQoqCgQCxZskQYDAZRVFQk5s+fL8xms9e+rzZv3iwyMzOFEEIYjUZRWVl5V79PSktLRWpqqqirqxNCWN4fR48e9bj3Cadc7mh4MWxZlq0Xw+5KwsLCrCMnf39/9OjRA3q9HtnZ2Zg4cSIAYOLEidbXferUKUyYMAGSJKF///6oqqpCWVkZcnJyMHToUAQFBSEoKAhDhw5FTk4OysrKUFNTg/79+0OSJEyYMMEr+rC0tBSnT5/GlClTAFguqXj+/HmMHTsWADBp0iSbPqkfZY4dOxbnzp2DEALZ2dlISkqCj48PIiIiEBUVhby8PK98X1VXV+PixYu4//77AQCyLCMwMPCuf58oigKDwQCz2QyDwYBu3bp53PuEUy53NOdi2F1JcXEx8vPzER8fj9u3b1svKxgWFoby8nIAlj5peLFsrVYLvV7v0Ffh4eFO19e393S7du3CE088gZqaGgBARUUFAgICoFarAfzy+oDGL4iu1+vRr18/6z4bPsbb3lfFxcUICQnBW2+9hZ9//hl9+/bFU089dVe/T8LDwzFt2jTMmzcPvr6+GDZsGPr27etx7xOO0O8QzbzQdVdQW1uL9evX46mnnkJAQECj7VrSJ5IkOW3v6b7//nuEhoZa/3JxpbE+aey1e+P7ymw2Iz8/H1OnTsUbb7wBjUaDAwcONNr+bnifVFZWIjs7G1u3bsX27dtRW1uLnJycRtu7633CEfodzbkYdldgMpmwfv163HfffRgzZgwAIDQ0FGVlZQgLC0NZWRlCQkIAWPqk4ZVW6vskPDwcFy5csK7X6/UYNGiQ0z4MDw/vpFfWOpcuXcKpU6dw5swZGAwG1NTUYNeuXaiurobZbIZarYZer7e+jvrXqNVqbS6Ibv/aGz7G295XWq0WWq3WOpIcO3YsDhw4cFe/T3788UdERERYX/OYMWNw6dIlj3ufcIR+R3Muhu3thBDYtm0bevTogQceeMC6PjExEV999RUA4KuvvsKoUaOs648fPw4hBH766ScEBAQgLCwMw4cPx9mzZ1FZWYnKykqcPXsWw4cPR1hYGPz9/fHTTz9BCIHjx497fB8+9thj2LZtG7Zu3YqFCxdiyJAhWLBgAQYPHoyTJ08CsBypUf86GrsgemJiIrKysmA0GlFcXIzCwkLEx8d75fuqW7du0Gq11ktE/vjjj+jZs+dd/T7R6XTIzc1FXV0dhBDWPvG09wm/KdrA6dOn8e6771ovhv3ggw+6u6R29Y9//AMrV65Er169rH/OPfroo+jXrx82btyIkpIS6HQ6LF682Ho42s6dO3H27Fn4+voiNTUVcXFxAIAjR45g//79ACyHo02ePBkAcPnyZbz11lswGAwYPnw4UlJSPH6Kod758+dx8OBBLFu2DEVFRQ6Ho/n4+MBgMGDLli3Iz8+3XhA9MjISAPDhhx/i6NGjUKlUeOqppzBixAgA3vm+unr1KrZt2waTyYSIiAikpqZCCHFXv0/27t2LrKwsqNVq9O7dG3PnzoVer/eo9wkDnYioi+CUCxFRF8FAJyLqIhjoRERdBAOdiKiLYKATEXURDHQioi6CgU5E1EX8f4b9I5Ga5jZBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=data['balance']\n",
    "count, bins_count = np.histogram(x, bins=1000)\n",
    "pdf = count / sum(count)\n",
    "cdf = np.cumsum(pdf)\n",
    "plt.plot(bins_count[1:], pdf, color=\"red\", label=\"PDF\")\n",
    "plt.plot(bins_count[1:], cdf, color=\"blue\", label=\"CDF\")\n",
    "plt.title('PDF and CDF of balance')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "Almost 100 percent of the datapoints lie under the balance range of 20000. So, it makes sence to delete the datapoints which\n",
    "has balance of over 20000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15a10274988>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1=data['duration']\n",
    "count, bins_count = np.histogram(x1, bins=1000)\n",
    "pdf = count / sum(count)\n",
    "cdf = np.cumsum(pdf)\n",
    "plt.plot(bins_count[1:], pdf, color=\"red\", label=\"PDF\")\n",
    "plt.plot(bins_count[1:], cdf, color=\"blue\", label=\"CDF\")\n",
    "plt.title('PDF and CDF of duration')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observation:\n",
    "Almost 100 percent of the datapoints lie under the duration range of 1500. So, it makes sence to delete the datapoints which\n",
    "has duration of over 1500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15a10186088>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEJCAYAAACE39xMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXgUVb4+8Ld6zUa2bgg3JAQIy2VTlrC6ABKZnyN6mQUQRHEYLgNREZWriAqMgiKPLCOgoDDBBcfIKDi4oBNWIahACBpgIJEACQmEdBJClk4vdX5/NN1QSTcJIVuF9/M8/dBVdar69Enz9rdPLyUJIQSIiEj1NE3dASIiqh8MdCKiFoKBTkTUQjDQiYhaCAY6EVELwUAnImohGOikSqdPn4YkSdi7d29Td6VelJSU4He/+x2Cg4MhSRJOnz5dr8eXJAkfffRRvR6Tmh8Gegv22GOPQZIkSJIEnU6HmJgYTJ8+HRaLxdPGvV2SJPj5+SE6OhoPPvggNm3aVO14HTp0ULR3X86fP9+Yd+uGlJeXY+HChbjtttsQEBCA8PBwDBo0CCtXrkR5eTkAYMGCBZ77otVqERoaiv79++O5555Ddna24ngbNmzwOgbTp0+/qX6+88472L9/P/bt24e8vDxER0ff1PHo1qRr6g5Qw7rrrrvw6aefwuFw4NChQ5g6dSqys7Px1VdfedqsWrUKf/jDH2C325GTk4OtW7fikUcewaZNm/DJJ59Ao7n6vP/8889j1qxZitto06ZNo92fG1FSUoJhw4YhNzcXr7zyCgYNGoSQkBAcPHgQb731FqKjozFmzBgArier/fv3QwiBkpISHD58GMuXL8eaNWuwbds2DB061HNcrVaLnJwcxW0FBATcVF8zMjLQs2dP9O7d+6aOQ7c4QS3W5MmTxciRIxXrFi5cKDQajSgvLxdCCAFAfPjhh9X23bp1qwAg3n//fc+6mJgY8eqrr9b69mVZFlOnThWdOnUSfn5+omPHjuKFF14QVqvV02b+/PkiNjZWbNmyRXTr1k0EBASI4cOHi8zMTMWxkpKSRGxsrDAajWLIkCHiiy++EADE999/7/P2n3jiCeHn5ydOnTrltW9FRUWKPlRls9nE4MGDRefOnYXT6RRCCJGYmCi0Wm2tx8B9nOeff15ERkYKvV4vunfvLjZu3OjZHhMTIwB4LsOGDfN6nJ07dwoA4l//+pcYMGCAMBqNokePHuK7775TtNuxY4fo3bu3MBqNonfv3mLHjh3V/s5z584V//3f/y38/f1FVFSU+Mtf/iKKi4uFEEKUlJSIoKAgRR+FECIrK0tIkiR27twphBBiy5Ytok+fPsLf31+EhISIAQMGiNTU1BsaG6pfnHK5xfj7+0OWZTgcjuu2Gz16NHr27IlPP/20zrclhEBERAQ+/vhjHD9+HCtWrEBiYiJee+01Rbu8vDy888472LhxI1JSUlBcXIwpU6Z4th8+fBgPPfQQxo4diyNHjmD27Nl46qmnrnvbsizj448/xsMPP4yOHTtW2y5JEkJDQ697DL1ej2effRaZmZlITU29gXuuNHfuXLz33ntYsWIF0tPTMWnSJEyaNAnbt28HABw4cADjxo3DXXfdhby8PHz++efXPd4zzzyDefPm4fDhwxg8eDAefPBBnDt3DgCQm5uL0aNHo3///khNTcXSpUu9jpW/vz/effddHDt2DBs2bMCuXbswc+ZMAECrVq0wceJEvPfee4p91q9fj86dO2PYsGE4f/48xo4diwkTJuDo0aPYv38/Zs2aBZ2OL/qbVFM/o1DDqVqhHz16VHTq1EkMGjTIsw4+KnQhhBg/frzo3r27ZzkmJkYYDAYRGBjouUyePPmG+rRs2TLRuXNnz/L8+fOFVqsV+fn5nnX/+Mc/hCRJoqKiQgghxMMPPyyGDBmiOM7KlSuvW6FfuHBBABBLly6tsU++KnQhhDh+/LgAIJKSkoQQrgodgGIMAgMDxYkTJ7zuX1ZWJgwGg1i9erVi/ZgxY8SIESM8y95eTVXlrtDXrVvnWWe320X79u3Fiy++KIQQ4sUXXxTt27cXdrvd08b9asvX31kIIT7//HNhMBg8r0QOHTokAIiTJ08KIYRwOBwiKipKLFmyRAghRGpqqgAgsrKyrttnalx8Om3hdu3ahaCgIDidTlRWVmLkyJFYu3ZtrfYVQkCSJMW6xx9/HAkJCZ7lVq1aXfcY7733HtatW4fTp0+jrKwMDocDsiwr2kRGRqJ169ae5Xbt2kEIgfz8fLRv3x7Hjh3DyJEjFfvceeedNfYdQLX+3yhvx9FqtUhLS1O0i4mJ8bp/ZmYmbDYb7r77bsX6YcOG4fXXX69Tn4YMGeK5rtPpMHDgQBw7dgwAcOzYMQwcOFBRKXsbq88//xwrVqxAZmYmSkpKIMsybDYbzp8/j8jISPTr1w9xcXFYt24d3njjDXzzzTe4cOECJk+eDAC47bbb8Jvf/Aa9evXCvffei+HDh+P3v/8938xtYpxyaeEGDRqEtLQ0HD9+HBUVFfj3v/+NTp061Wrf9PR0xMbGKtaFh4ejc+fOnktERITP/Tdt2oTHH38c48ePx9dff43Dhw9j3rx5sNvtinYGg0Gx7A5Pd/B7e2KpSevWrREWFoajR4/e0H5VpaenA0C1cbh2DDp37gy9Xn/d41Ttf13uky/imh9M9Xbcqss//vgjxo4di7vvvhubN29Gamoq1qxZAwCw2WyedtOnT8eGDRtgt9uxbt06jBkzxvMGuFarxTfffIMdO3ZgwIAB+Oyzz9C1a1d8+eWX9XKfqG4Y6C2cv78/OnfujA4dOsBoNNZ6v61bt+LYsWMYP358nW97z5496Nu3L5555hn0798fXbp0qdPnq3v27Il9+/Yp1lVdrkqj0WDixInYuHEjsrKyqm0XQuDSpUvXPYbdbseyZcvQtWtX9OnT54b7DbiC32g0Yvfu3Yr1e/bsQc+ePet0zB9++MFz3eFw4MCBA+jevTsA11j9+OOPcDqdnjZVP6u/d+9emM1mLFy4EIMGDULXrl2rfWoHAB566CFYrVasXbsWX331Ff73f/9XsV2SJAwcOBBz587Fnj17MGzYMCQmJtbpPlH9YKATLl26hPPnzyM7Oxv79+/H3LlzMW7cODz00EOYMGFCnY/brVs3/PLLL/jiiy/w66+/4m9/+1uNb/h58/TTT2P//v148cUXcfLkSWzevBlLly6tcb9FixahS5cuGDx4MN59910cOXIEWVlZ2Lx5M4YNG4adO3d62jqdTpw/fx7nz5/HiRMn8Mknn+DOO+/EsWPH8P777ys+unkjAgICMHPmTLz88svYtGkTMjIy8Nprr+GLL77A3Llz63TMxYsX4+uvv8bx48cxY8YMXLhwATNmzAAAzJgxAxcvXsS0adNw/PhxbN++HS+++KJi/27duuHixYtYv349Tp06hQ8++ABvv/12tdsJDAzEpEmT8Oyzz6J9+/aIj4/3bEtJScGrr76KH3/8EWfPnsX27dvx888/o0ePHnW6T1RPmmz2nhpcbd5owzUflzMYDKJdu3bigQceEJ9++mm1tjf6sUWbzSamTZsmwsLCRKtWrcSECRM8b2a6eXtD8vvvv6/2hts//vEP0alTJ2EwGMTAgQPFli1bavzYohBClJaWigULFoiePXsKPz8/ERoaKgYOHChWrVrl+ejm/PnzPWMgSZIIDg4Wffv2Ff/3f/8nsrOzFcdriI8tCnFjb4p+8cUXol+/fsJgMIju3buLbdu2KdolJyeLXr16CYPBIHr27Cm2b99e7U3Rl156SbRp00YEBASI++67T3z88cde3+RMS0sTAMRrr72mWJ+eni7uu+8+ERERIQwGg2jfvr2YPXu2qKysvKGxofolCcEzFhGpwa5duzBixAhkZ2cjKiqqUW7z66+/xpgxY3D27Fm0bdu2UW6T6o6fciGiasrLy3H27Fm88sormDhxIsNcJTiHTkTVLFmyBL169YJGo8GSJUuaujtUS5xyISJqIVihExG1EAx0IqIWoknfFM3Nza3TfmazGQUFBfXcm5aD4+Mbx8Y3jo1vzWlsIiMjfW5jhU5E1EIw0ImIWggGOhFRC9GsvlgkhIDVaoUsy9f9JboLFy6gsrKyEXt2c4QQ0Gg08PPzq7df2CMiqqpZBbrVaoVer6/xrCc6nQ5arbaRelU/HA4HrFYr/P39m7orRNRC1Rjob7/9NlJTUxESEuL1F+6EEEhMTMThw4dhNBqRkJBQ69/brkqW5RZ7CiudTqeqVxVEpD41zqEPHz78uj/zefjwYZw/fx5vvfUWpk2bhnXr1tW5My19OqKl3z8ialo1lsM9evRAfn6+z+0HDx7E3XffDUmS0LVrV5SVlaGoqAhhYWH12lEiql9CuC6y7LpYrUBFBQBIcP8giLvNtZeq693tr7fPtduubV91m9MJCFF9u/f23tvJsu/bqXpxOCTYbBIqKwGnU/Ls6/7XdV1CYKAGJSUBivVCeG9f9ThXx+Tq+lGjrOjTR3nmrvpw0/MbhYWFMJvNnmWTyYTCwkKvgZ6cnIzk5GQArh/pv3Y/wPVmZ22nXBpqaua//uu/0L17dzgcDnTt2hVvvfUWAgICFOu1Wi3Gjx+PadOmQaPRYN++fZg8eTLat28PwHWatn/+85/Vjm00Gqvd54ag0+ka5XbUqD7HRgigvBwoLXVdysqka64DpaUSLl92tXE6XReHQ/Jcd18qKwG73fWf3+Fwt7va3uFwbbfZXP86HN7b2WyuUHYHtNN59XrVizs4q/P9pRUKrZejSJJAly7+iI+Xa258g246Fb39tpevqYX4+HjFWU+qfvOqsrKyVm926nQ6OByOG+xp7fj5+eG7774DADzxxBNITEzEX/7yF8X6goICPP744yguLsbs2bPhdDoxcOBAfPDBB57jeOtfZWVlo3zbrDl9q605sNlc4Wq1SvD3D8e5c8UoLdWgtFS6EsLK62Vl3teXl0tXglWC3e6q6ryH4vVpNAJaLaDVuq4bDIBe714noNMBGg2g011tZzAI6PWubUajQGAgPO2vbePnJzzH1WgASXIdy3UR11y/ug5w7R8UFIDy8nJIkms/wBU+V6+jyrZrL1fbVd/mbb/qx3X3w9Vvcd3jXHu7Vdu57/fV4wqf++t0Akaja+y0WuX4uI8FCJjN4SgqKlRsc98H5TrlOPsaAwCo63/R631T9KYD3WQyKcLDYrG0mOmWgQMH4vjx49XWm81mLFmyBL/97W/x7LPPNkHP6FqFhRJOntQjN1eLggINioo0sFg0OHVKh7NntcjN1VYJ3jY+j+XvLyMoSCAwUCAoyHW9dWsZHTs64O9/NXyNRgG9HggKEggIkBEYKDyXgICrxwgMFPD3F4qgbq5vpZjNfigoKG3qbjRLZjNgNNZ/RV3fbjrQ4+LisG3bNtxxxx3IyMhAQEBAvQR68Lx50B875nWbJEleXxnUxN6jB0peeaVWbR0OB3bu3Inhw4d73R4TEwMhhOfJ7KeffsK9994LABg9ejSeeuqpG+4f3ZjLlyW89VYQ1qwJgixfTUmtViA0VEaHDk4MGmRDhw5OhIbK8PMTaN06CLJcgsBAV+i6gvdqAKvs07BECjUG+ooVK3Ds2DFcvnwZ06dPx7hx4zzTCaNGjULfvn2RmpqKmTNnwmAwICEhocE73ZCsVqsnmAcNGnTdkyRf+6RSdcqFGkZpqYRDhwz47DN/fPutH0pLNbj3XismTy5DdLQDZrOM4GABX+d0NpsDUFBgbdxOEzWSGgN91qxZ190uSRKmTp1abx1yu14l3dBz6P/+979rbHfmzBloNBqYzWZkZGQ0SF/oqpMndfjySz+sWxeES5c0CAqSMWqUFX/+c1mDfFqASI1a5rd4GpjFYsGcOXPwpz/9iZ8tb2CZmVp8+GEg1q0LAgCMGGHFY4+V4Y47KsEv3RIpMdBryT0V4/7Y4h//+EdMmzatqbvVYhUVSViwIAT//GcAJElgwoQyPPlkKWJinE3dNaJmi4Feha/pk+zsbJ/7DB06FEOHDm2oLt0SZBk4cMCAr7/2w759Rhw/rodGI5CQcBmTJpUzyIlqgYFOTaK8XMKpU1ocOmTAwYMGfPONHyoqNDAaBfr2teH550swbFglbr+d8+NEtcVApwZVViYhJcWAo0f1OHFCj3PntMjL0yA39+pDLyzMidGjrRgxwoqRIysRFHTjH0klIgY61aOKCiAzU49ff9Vhzx4j0tL0yMrSwWZzvXEcE+NAdLQTQ4fa0LFjOWJjHejZ046OHZ3N9ss2RGrCQKc6qagA9u41Ij1dj9RUA7KztTh9Wge73ZXMoaEy4uJsuOeeStxzjxW3325HYCArb6KGxECnWrNaga1bXV/o+f57I0pLNZAkgW7dHOja1YF773UFd4cODnTv7uC3LokaGQOdfBICyMvTICXFiG+/9cOuXUaUl2vQpo0To0dX4H/+x4q+fW1o1YqVN1FzwED3Ij8/H/Pnz8eRI0dgMBgQHR2NBQsWYNSoUYiNjUVlZSWCgoIwefJkjBs3DgCQlJSEhQsXom3btgCA7t2746233mrKu1ErFRUSzp7V4swZLbKzdThzRoucHC3OnnVdLy93fYe+bVsn/vCHCtx/fwXuvNPGOW+iZoiBXoUQAn/+858xduxYvPPOOwCA9PR0FBQUICYmxvMTumfOnMHUqVMhhMD48eMBAA8++CAWLVrUZH2v6tw5LQ4d0sNi0cBi0aKoSIOSEgkWi+sXCfPytLh4UTkvEhAgIyrKiehoJ+64oxKdOjlw++123Hab3efvoxBR88BAr2Lfvn3Q6/V49NFHPet69epV7YtFMTExmD9/Pl555RVPoDe106e12L3biMOHtdi9OwL5+cqwDgmRERwsw2SSYTbL6NnTjvbtnZ5Pn8TEOBEeLrP6JlKpZhvo8+YF49gxvddtdf353B497HjllZLrtjlx4gR69+5dq+P17t0bv/76q2f5X//6F3766ScAwNSpUxst6K1W4O9/D8Lrr7eCLEuIjBS4444K9Oljx6BBNrRt60RYmIwWev5tIrqC/8VvQtUnlaaYctm/34CZM0ORm6vDqFEVePnlEgwYEAaLpbhR+0FETa/ZBvr1KumG/Pncrl274quvvqpV2/T0dHTu3LlB+lEbP/xgwKOPhqNtWxmffFKAu+6yAWi+Z8QhoobFt7mquPPOO2Gz2bBx40bPurS0NOTk5CjaZWdn49VXX8WUKVMau4sAgHPnNJg8ORwA8MEHFk+YE9Gtq9lW6E1FkiSsW7cO8+fPx+rVq2E0GhEVFYW//vWvOHPmDEaNGuX52OKUKVOa7A3RN94IhtMJbN9+kb9ESEQAAEnU5d3FepKbm6tYLi8vR0BAQI37NeSUS0Oq7f2ridMJ9OjRFg88UIE337xUbbvZbFacuJuu4tj4xrHxrTmNTWRkpM9tnHJRoZMndSgt1WDwYE6zENFVDHQV2rzZde61vn0Z6ER0VbMK9Cac/WkU9XH/hAA2bgyEJAl07Mi5cyK6qlkFukajUeXceG04HA5o6uG78+npehQXa/Dss5f5VXwiUmhWn3Lx8/OD1WpFZWUlpOt8mNpoNKKysrIRe3ZzhBDQaDTw8/Or8zFkGUhMDMSyZa0QEeHEww+X12MPiaglaFaBLkkS/P39a2zXnN5xbmiyDGzb5ocVK1rh6FE9evWy4Z13itCmjdzUXSOiZqZZBTq5zgR06pQOGRl6pKQYsHOnEbm5OnTo4MCyZUUYN66C3wQlIq8Y6E2svFzCsWM6JCUFYOdOP5w/r4EQrsQOCpJx112VeOmlEowebeUZgIjouhjojchi0eDIET2OHNHj55/1+M9/9Dh71vUn8POTce+9lejWzY5OnRzo0sV10Xv/wUkiomoY6A0oJ0eLnTuNOHjQgJ9+MnjCW5IEYmMd6NPHjnHjytGtmwMDB9pgNnNenIjqjoFeT4QAjh7V4eBBA44cMeCXX/Q4ftxVXoeHOzF4sA2PPlqG22+3o3dvO8/DSUT1joFeD3JytHjkkXCcPOkKcLPZidtus2P48Er88Y+uCpxvZBJRQ2Og3wRZBjZuDMDixcGw2YB58y7h/vutaNfOyQAnokZXq0BPS0tDYmIiZFnGyJEjMWbMGMX2goICrF69GmVlZZBlGRMnTkS/fv0apMPNycaNAZgzJxTdu9vx7ruF6NSJX8UnoqZTY6DLsoz169fjpZdegslkwgsvvIC4uDhERUV52nz22WcYMmQIRo0ahZycHLz++ustPtBzczVYuDAYQ4ZU4tNPLfwaPhE1uRpjKDMzE23btkVERAR0Oh2GDh2KAwcOKNpIkoTyctdX0cvLyxEWFtYwvW1G3nwzGBUVEt58s5hhTkTNQo0VemFhIUwmk2fZZDIhIyND0Wbs2LFYuHAhtm3bhsrKSrz88stej5WcnIzk5GQAwOLFi2E2m+vWaZ2uzvvWh59+kpCUpMcDD8iIi2t+T15NPT7NGcfGN46Nb2oZmxoD3dtPvlb94ax9+/Zh+PDheOCBB3Dy5EmsXLkSS5curfbrgvHx8YiPj/cs1/X3WJr6t1y+/DIIgB7PPXcRBQXNb968qcenOePY+Max8a05jc1NnbHIZDLBYrF4li0WS7UplR07dmDIkCEAgK5du8Jut+Py5ct17W+zd+iQAbGxdr4JSkTNSo2BHhsbi7y8POTn58PhcCAlJQVxcXGKNmazGenp6QCAnJwc2O12BAcHN0yPm5gQQGqqHv3725u6K0RECjVOuWi1WkyZMgWLFi2CLMsYMWIEoqOjkZSUhNjYWMTFxeHRRx/F2rVr8dVXXwEAEhISrvt75mr28896FBZqERfH078RUfMiiSY871tubm6d9muq+ayffjJgwoRwBAUJ7N6dj9DQ5vn1/eY039fccGx849j41pzG5qbm0AkoKpLw0UcBmDIlDE6nhI8/tjTbMCeiWxe/+g/XvHhBgQbZ2VpkZ2uRk6O78q9r+exZHWw2Cb162bB6tQWdO7fM854Skbq1mEB3OoGyMglWq+ty+bKES5c0KC7W4NIlDS5dkrxeLy7WoKBAg9JS5YuVsDAnoqOd6NrVgfj4Stx3XwX69rXzJBNE1GypLtDPp17Enh8vYld+R5Rc1iIjQ4+cHC0KCjRwOK7/RqxWKxASIiMkRCA0VEZoqIwOHRwID5fRsaMT0dEOREc7ERXlRFAQp1SISF1UF+hfrcjDvO3/D0aDjLBwgagoJ4YNq0Tr1k6Ehcnw8xPw9xcICnKFtyu4XdeDggR/BZGIWizVBfrveqRj+PZFaJ/6d+jDApu6O0REzYbqPuUSHVqCu7AXBkNT94SIqHlRXaB7NN3H54mImiX1BjoRESmoN9BZoRMRKagv0PkxFSIir9QX6G6s0ImIFNQX6KzQiYi8Ul+gu7FCJyJSUF+gs0InIvJKfYHuxgqdiEhBfYHOCp2IyCv1BbobK3QiIgX1Bbq7QmegExEpqDfQiYhIQX2BfgVjnYhISXWBLlihExF5pbpA9+AcOhGRgvoCnRU6EZFX6gt0N1boREQK6g10IiJSUG+gs0InIlJQX6BzDp2IyCv1BbobK3QiIgX1BTordCIir3S1aZSWlobExETIsoyRI0dizJgx1dqkpKRg06ZNkCQJMTExeOqpp+q9swqs0ImIFGoMdFmWsX79erz00kswmUx44YUXEBcXh6ioKE+bvLw8bNmyBa+++iqCgoJw6dKlhusxK3QiIq9qnHLJzMxE27ZtERERAZ1Oh6FDh+LAgQOKNtu3b8dvfvMbBAUFAQBCQkIaprfXYoVORKRQY4VeWFgIk8nkWTaZTMjIyFC0yc3NBQC8/PLLkGUZY8eORZ8+faodKzk5GcnJyQCAxYsXw2w233CHNa1aAQDCw8OBOux/K9DpdHUa21sBx8Y3jo1vahmbGgNdeKmEpSrTHrIsIy8vD/Pnz0dhYSHmzZuHpUuXIjAwUNEuPj4e8fHxnuWCgoIb7nBAaSlCARRaLJANhhve/1ZgNpvrNLa3Ao6Nbxwb35rT2ERGRvrcVuOUi8lkgsVi8SxbLBaEhYUp2oSHh2PAgAHQ6XRo06YNIiMjkZeXdxNdvg7OoRMReVVjoMfGxiIvLw/5+flwOBxISUlBXFycos3AgQORnp4OACgpKUFeXh4iIiIapsdunEMnIlKoccpFq9ViypQpWLRoEWRZxogRIxAdHY2kpCTExsYiLi4Ot99+O44cOYKnn34aGo0GkyZNQqsrc931jqegIyLyqlafQ+/Xrx/69eunWDd+/HjPdUmSMHnyZEyePLl+e+cNp1yIiLxS3zdFr2CsExEpqS7QeQo6IiLvVBfoHpxDJyJSUF+gs0InIvJKfYHuxgqdiEhBvYFOREQK6g10VuhERArqC3TOoRMReaW+QHdjhU5EpKC+QGeFTkTklfoC3Y0VOhGRgvoCnRU6EZFX6gt0N1boREQK6gt0VuhERF6pL9DdWKETESmoL9BZoRMReaW+QHdjhU5EpKC+QOcp6IiIvFJvoBMRkYL6Av0KxjoRkZLqAp2noCMi8k51ge7BOXQiIgX1BjoRESmoN9BZoRMRKagv0DmHTkTklfoC3Y0VOhGRgvoCnRU6EZFX6gt0N1boREQK6gt0VuhERF6pL9DdWKETESmoL9BZoRMReVWrQE9LS8NTTz2FJ598Elu2bPHZ7ocffsC4cePw66+/1lsHfWKFTkSkUGOgy7KM9evXY+7cuVi+fDn27duHnJycau0qKirwzTffoEuXLg3SUQ9W6EREXtUY6JmZmWjbti0iIiKg0+kwdOhQHDhwoFq7pKQkPPjgg9Dr9Q3S0WpYoRMRKehqalBYWAiTyeRZNplMyMjIULTJyspCQUEB+vfvj61bt/o8VnJyMpKTkwEAixcvhtlsvuEOSyEhAICwsDCIOux/K9DpdHUa21sBx8Y3jo1vahmbGgNdeKmEpWumPWRZxvvvv4+EhIQabyw+Ph7x8fGe5YKCgtr208OvpAThAIoKC+Gow/63ArPZXKexvRVwbHzj2PjWnMYmMjLS57YaA91kMsFisXiWLRYLwsLCPMtWqxXZ2dn461//CvdmBmcAAA5tSURBVAAoLi7GkiVL8NxzzyE2NvZm+u0d59CJiLyqMdBjY2ORl5eH/Px8hIeHIyUlBTNnzvRsDwgIwPr16z3LCxYswCOPPNIwYQ4w0ImIfKgx0LVaLaZMmYJFixZBlmWMGDEC0dHRSEpKQmxsLOLi4hqjn9VIfFOUiEihxkAHgH79+qFfv36KdePHj/fadsGCBTfdqevhKeiIiLxT3zdF3VihExEpqDfQiYhIQb2BzgqdiEhBfYHOOXQiIq/UF+hurNCJiBTUF+is0ImIvFJfoLuxQiciUlBfoLNCJyLySn2B7sYKnYhIQX2BzgqdiMgr9QW6Gyt0IiIF9QU6K3QiIq/UF+hurNCJiBTUF+is0ImIvFJfoLuxQiciUlBfoF+p0FmnExEpqTbQiYhISX2B7sYpFyIiBdUFOmOciMg71QW6Byt0IiIF9QU659CJiLxSX6C7sUInIlJQX6CzQici8kp9ge7GCp2ISEF9gc4KnYjIK/UFuhsrdCIiBfUFOit0IiKv1BfobqzQiYgU1BforNCJiLxSX6C7sUInIlLQ1aZRWloaEhMTIcsyRo4ciTFjxii2f/nll9i+fTu0Wi2Cg4MxY8YMtG7dukE6zAqdiMi7Git0WZaxfv16zJ07F8uXL8e+ffuQk5OjaNOhQwcsXrwYb775JgYPHoyPPvqowTrswQqdiEihxkDPzMxE27ZtERERAZ1Oh6FDh+LAgQOKNr169YLRaAQAdOnSBYWFhQ3TW4AVOhGRDzVOuRQWFsJkMnmWTSYTMjIyfLbfsWMH+vTp43VbcnIykpOTAQCLFy+G2Wy+0f5CCgkBAIQEB0PUYf9bgU6nq9PY3go4Nr5xbHxTy9jUGOjCy9SG5KNK3rNnD06dOoUFCxZ43R4fH4/4+HjPckFBQS27eZWhpARmACWXLqGyDvvfCsxmc53G9lbAsfGNY+NbcxqbyMhIn9tqnHIxmUywWCyeZYvFgrCwsGrtfv75Z2zevBnPPfcc9Hp9HbtaC5xyISLyqsZAj42NRV5eHvLz8+FwOJCSkoK4uDhFm6ysLLz33nt47rnnEHJlSqTB8U1RIiKFGqdctFotpkyZgkWLFkGWZYwYMQLR0dFISkpCbGws4uLi8NFHH8FqtWLZsmUAXC9Pnn/++QbpMGOciMi7Wn0OvV+/fujXr59i3fjx4z3XX3755frtVW2wQiciUlDfN0U5h05E5JX6At2NFToRkYL6Ap0VOhGRV+oLdDdW6ERECuoLdFboREReqS/Q3VihExEpqC/QWaETEXmlvkB3Y4VORKSgvkBnhU5E5JX6At2NFToRkYL6Ap0VOhGRV+oLdDdW6ERECuoLdFboREReqS/QiYjIK/UF+pUKXeKUCxGRguoCXXDKhYjIK9UFugcrdCIiBfUGOhERKag30FmhExEpqC/QOYdOROSV+gLdjRU6EZGC+gKdFToRkVfqC3Q3VuhERArqC3RW6EREXqkv0N1YoRMRKagv0FmhExF5pb5Ad2OFTkSkoL5AZ4VOROSV+gLdjRU6EZGC+gKdFToRkVfqC3Q3VuhERAq62jRKS0tDYmIiZFnGyJEjMWbMGMV2u92OVatW4dSpU2jVqhVmzZqFNm3aNEiHm0OFbtyzB/q0NJTOnNkkt685dw7GfftQMWYMYDA0SR+IqPmpsUKXZRnr16/H3LlzsXz5cuzbtw85OTmKNjt27EBgYCBWrlyJ+++/Hxs3bmywDjcZIaA5dw5+X3wB04QJCH7jDYTOmgX9wYOQSkuhzcwEZFm5T0UFYLPV7vhV961y27DZoMnLg1RSgrYDByLs6afR+v77YfzuO2jy8gCHA5qLF+t+/2qrEV8ZSaWlrtuTZUiXL3u9fam0FNKlS3zFRoRaVOiZmZlo27YtIiIiAABDhw7FgQMHEBUV5Wlz8OBBjB07FgAwePBg/P3vf4cQAlJDVNNXjhmekADHG29AqqyE8PNzbXM6Aa3W00ZcuS45ncrAdP/nv/ZfL+vcp7mTyspcgWq1KroSsGkTAjZtUqxzmkyu2wMgWa0QkgQREqK8nSoX6UpgiVatXPdFlgG7HZIQkKxWSFVu101/7BhMf/qT69CSBEkICIMBCA5GhBAQwcGAwwHJ4YDQaFzHdv9N3Pfv2vt+TR+ligrXWAoBTXExhEbjGku73dNODg0FtFoIvd71SsFud/0NAEh2OySbDXA4IIKCIPR6Vz/8/V33x327slx9PCorAYMBmuLiavdZaLWu29XrIZWUQFNe7hl30aqV62+u8V2n6LRatL7SxwbXXJ5katmPhhybZnPKyDr2Q6vVok09js3l2bNdr7DrWY2BXlhYCJPJ5Fk2mUzIyMjw2Uar1SIgIACXL19GcHCwol1ycjKSk5MBAIsXL4bZbL7xHoeFQcyeDfncOdcThtHoClwA0Ok8geIJSlm++p/cHWaSpLxewzpxJXgcnTtDs3cvnFOnQsrMBNq1A7KyIBUVudqWlwNCQLhDLy8PCAwEQkKqH/+ai5AkV+Dl5gKtWnmCVFRWQrRqBTgcQFgYpMxMiMhIwN8fwmwG2rWD9O23QMeOrtsKDwfy8qAJDAQKC13jo9cDOp1rLCoqXA9oH/1QrNdoXGHr5wdZloGgIKCszHUKQLvdddwrYSw5HEBlJWA0evoOgwHCaHT9TYqLXeFuNLr64Od39YnXy0U4HAAAp04HBAQAhYWuY1++DEREABaLq38lJXB26gTpP/8BAgMhSZLrfjqdvk9VKEnQNGa4NIMpQgC160dDj42axsLLPvX5pBTUsSMC65J/Nagx0IWXO1G18q5NGwCIj49HfHy8Z7mgoKBWnazKvGhRnfe9aVOnuv69886muf2qRo6stspsNjfd+DRzHBvfODa+NcjY1PF4kZGRPrfVOIduMplgsVg8yxaLBWFhYT7bOJ1OlJeXIygoqE6dJSKiuqkx0GNjY5GXl4f8/Hw4HA6kpKQgLi5O0aZ///7YtWsXAOCHH35Az549G2b+nIiIfKpxykWr1WLKlClYtGgRZFnGiBEjEB0djaSkJMTGxiIuLg733HMPVq1ahSeffBJBQUGYNWtWY/SdiIiuIQlvE+CNJDc3t077ca7v+jg+vnFsfOPY+Nacxuam5tCJiEgdGOhERC0EA52IqIVgoBMRtRBN+qYoERHVH1VW6HPmzGnqLjRrHB/fODa+cWx8U8vYqDLQiYioOgY6EVELocpAv/YHvqg6jo9vHBvfODa+qWVs+KYoEVELocoKnYiIqmOgExG1ELU6SXRzUtMJq1u6goICrF69GsXFxZAkCfHx8fjtb3+L0tJSLF++HBcvXkTr1q3x9NNPIygoCEIIJCYm4vDhwzAajUhISECnTp2a+m40KFmWMWfOHISHh2POnDnIz8/HihUrUFpaio4dO+LJJ5+ETqdr3JObNwNlZWVYs2YNsrOzIUkSZsyYgcjISD5urvjyyy+xY8cOSJKE6OhoJCQkoLi4WF2PHaEiTqdTPPHEE+L8+fPCbreL2bNni+zs7KbuVqMqLCwUv/76qxBCiPLycjFz5kyRnZ0tPvzwQ7F582YhhBCbN28WH374oRBCiEOHDolFixYJWZbFiRMnxAsvvNBkfW8sW7duFStWrBCvv/66EEKIpUuXir179wohhFi7dq349ttvhRBCbNu2Taxdu1YIIcTevXvFsmXLmqbDjWTlypUiOTlZCCGE3W4XpaWlfNxcYbFYREJCgqisrBRCuB4zO3fuVN1jR1VTLteesFqn03lOWH0rCQsL81RK/v7+aNeuHQoLC3HgwAEMGzYMADBs2DDPuBw8eBB33303JElC165dUVZWhqKioibrf0OzWCxITU3FyCun5hNC4OjRoxg8eDAAYPjw4YqxGT58OADXyc3T09O9nk6xJSgvL8fx48dxzz33AAB0Oh0CAwP5uLmGLMuw2WxwOp2w2WwIDQ1V3WNHVVMutTlh9a0kPz8fWVlZ6Ny5My5duuQ5NWBYWBhKSkoAuMbs2pNxm0wmFBYWVjuNYEuxYcMGTJo0CRUVFQCAy5cvIyAgAFqtFgAQHh6OwsJCALU/uXlLkJ+fj+DgYLz99ts4c+YMOnXqhMcee4yPmyvCw8PxwAMPYMaMGTAYDLj99tvRqVMn1T12VFWhe3sGvFVPdWe1WrF06VI89thjCAgI8NnuVhqzQ4cOISQkpNZzvbfS2DidTmRlZWHUqFFYsmQJjEYjtmzZ4rP9rTQ2AFBaWooDBw5g9erVWLt2LaxWK9LS0ny2b67jo6oKvTYnrL4VOBwOLF26FHfddRcGDRoEAAgJCUFRURHCwsJQVFTkqRRMJpPiTCstecxOnDiBgwcP4vDhw7DZbKioqMCGDRtQXl4Op9MJrVaLwsJChIeHA7j6eDKZTC3+5OYmkwkmkwldunQB4Jom2LJlCx83V/zyyy9o06aN5/4PGjQIJ06cUN1jR1UVem1OWN3SCSGwZs0atGvXDqNHj/asj4uLw+7duwEAu3fvxoABAzzr9+zZAyEETp48iYCAgBb7H3PixIlYs2YNVq9ejVmzZqFXr16YOXMmevbsiR9++AEAsGvXLs9j5lY6uXloaChMJpPntI+//PILoqKi+Li5wmw2IyMjA5WVlRBCeMZHbY8d1X1TNDU1Fe+//77nhNW///3vm7pLjeo///kP5s2bh/bt23seQBMmTECXLl2wfPlyFBQUwGw245lnnvF8/Gz9+vU4cuQIDAYDEhISEBsb28T3ouEdPXoUW7duxZw5c3DhwoVqHz3T6/Ww2WxYtWoVsrKyPCc3j4iIaOquN5jTp09jzZo1cDgcaNOmDRISEiCE4OPmik8//RQpKSnQarXo0KEDpk+fjsLCQlU9dlQX6ERE5J2qplyIiMg3BjoRUQvBQCciaiEY6ERELQQDnYiohWCgExG1EAx0IqIW4v8Dt5RZXKIsTVcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x2=data['pdays']\n",
    "count, bins_count = np.histogram(x2, bins=1000)\n",
    "pdf = count / sum(count)\n",
    "cdf = np.cumsum(pdf)\n",
    "plt.plot(bins_count[1:], pdf, color=\"red\", label=\"PDF\")\n",
    "plt.plot(bins_count[1:], cdf, color=\"blue\", label=\"CDF\")\n",
    "plt.title('PDF and CDF of pdays')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "Almost 100 percent of the datapoints lie under the pdays range of 400. So, it makes sence to delete/modify the datapoints which\n",
    "has pdays of over 400."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15a1016a508>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x3=data['campaign']\n",
    "count, bins_count = np.histogram(x3, bins=1000)\n",
    "pdf = count / sum(count)\n",
    "cdf = np.cumsum(pdf)\n",
    "plt.plot(bins_count[1:], pdf, color=\"red\", label=\"PDF\")\n",
    "plt.plot(bins_count[1:], cdf, color=\"blue\", label=\"CDF\")\n",
    "plt.title('PDF and CDF of campaign')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "Almost 100 percent of the datapoints lie under the campaign range of 10. So, it makes sence to delete/modify the datapoints which has campaign of over 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15a10028a08>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x4=data['previous']\n",
    "count, bins_count = np.histogram(x4, bins=1000)\n",
    "pdf = count / sum(count)\n",
    "cdf = np.cumsum(pdf)\n",
    "plt.plot(bins_count[1:], pdf, color=\"red\", label=\"PDF\")\n",
    "plt.plot(bins_count[1:], cdf, color=\"blue\", label=\"CDF\")\n",
    "plt.title('PDF and CDF of previous')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "Almost 100 percent of the datapoints lie under the previous range of 10. So, it makes sence to delete/modify the datapoints which has previous of over 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data after removing rows based on balance:  (11105, 17)\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/13851535/how-to-delete-rows-from-a-pandas-dataframe-based-on-a-conditional-expression\n",
    "# data = data.drop(data[ (data.duration == 1042) | (data.duration == 1467)  ].index)\n",
    "data = data.drop(data[ data.balance > 20000].index)\n",
    "print('Shape of data after removing rows based on balance: ',data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data after removing rows based on duration:  (10956, 17)\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(data[ data.duration > 1500].index)\n",
    "print('Shape of data after removing rows based on duration: ',data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data after removing rows based on pdays:  (10822, 17)\n"
     ]
    }
   ],
   "source": [
    "# data_test = data_test.drop(data_test[ (data_test.duration == 1042) | (data_test.duration == 1467)  ].index)\n",
    "# indexNames = data_test[ (data_test.duration > 1042)].index & data_test[(data_test.duration < 1467)  ].index\n",
    "# data_test.drop(indexNames , inplace=True)\n",
    "data = data.drop(data[ data.pdays > 400].index)\n",
    "print('Shape of data after removing rows based on pdays: ',data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data after removing rows based on campaign:  (10614, 17)\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(data[ data.campaign > 10].index)\n",
    "print('Shape of data after removing rows based on campaign: ',data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data after removing rows based on previous:  (10523, 17)\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(data[ data.previous > 10].index)\n",
    "print('Shape of data after removing rows based on previous: ',data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding Categorical Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_mappings:  {0: 'admin.', 1: 'blue-collar', 2: 'entrepreneur', 3: 'housemaid', 4: 'management', 5: 'retired', 6: 'self-employed', 7: 'services', 8: 'student', 9: 'technician', 10: 'unemployed', 11: 'unknown'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "marital_mappings:  {0: 'divorced', 1: 'married', 2: 'single'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "education_mappings:  {0: 'primary', 1: 'secondary', 2: 'tertiary', 3: 'unknown'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "default_mappings:  {0: 'no', 1: 'yes'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "housing_mappings:  {0: 'no', 1: 'yes'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "loan_mappings:  {0: 'no', 1: 'yes'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "contact_mappings:  {0: 'cellular', 1: 'telephone', 2: 'unknown'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "month_mappings:  {0: 'apr', 1: 'aug', 2: 'dec', 3: 'feb', 4: 'jan', 5: 'jul', 6: 'jun', 7: 'mar', 8: 'may', 9: 'nov', 10: 'oct', 11: 'sep'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "poutcome_mappings:  {0: 'failure', 1: 'other', 2: 'success', 3: 'unknown'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "deposit_mappings:  {0: 'no', 1: 'yes'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "categorical_features=['job','marital','education','default','housing','loan','contact','month','poutcome','deposit']\n",
    "for feature in categorical_features:\n",
    "    encoder=LabelEncoder()\n",
    "#     exec(\"%s = %d\"%(labels_coulumn=encoder.fit_transform(data[feature])))\n",
    "    labels_coulumn=encoder.fit_transform(data[feature])\n",
    "    mappings = {index: label for index, label in \n",
    "                      enumerate(encoder.classes_)}\n",
    "    print('%s_mappings: '%(feature),mappings)\n",
    "    data[feature]=labels_coulumn\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-6847</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3058</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1467</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2712</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1389</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2282</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2049</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>673</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  default  balance  housing  loan  contact  \\\n",
       "0   59    0        1          1        0    -6847        1     0        2   \n",
       "1   56    0        1          1        0    -3058        0     0        2   \n",
       "2   41    9        1          1        0    -2712        1     0        2   \n",
       "3   55    7        1          1        0    -2282        1     0        2   \n",
       "4   54    0        1          2        0    -2049        0     0        2   \n",
       "\n",
       "   day  month  duration  campaign  pdays  previous  poutcome  deposit  \n",
       "0    5      8      1042         1     -1         0         3        1  \n",
       "1    5      8      1467         1     -1         0         3        1  \n",
       "2    5      8      1389         1     -1         0         3        1  \n",
       "3    5      8       579         1     -1         0         3        1  \n",
       "4    5      8       673         2     -1         0         3        1  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-6847</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  default  balance  housing  loan  contact  \\\n",
       "0   59    0        1          1        0    -6847        1     0        2   \n",
       "\n",
       "   day  month  duration  campaign  pdays  previous  poutcome  \n",
       "0    5      8      1042         1     -1         0         3  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before we go ahead and build any machine learning models from this data, let's split the data with 80:20.\n",
    "y = data['deposit'].values\n",
    "X = data.drop(['deposit'], axis=1)\n",
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:  (10523, 16)\n",
      "Shape of y:  (10523,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X: ',X.shape)\n",
    "print('Shape of y: ',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into Train-Test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (8418, 16)\n",
      "Shape of X_test:  (2105, 16)\n",
      "Shape of y_train (8418,)\n",
      "Shape of y_test (2105,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "print('Shape of X_train: ',X_train.shape)\n",
    "print('Shape of X_test: ', X_test.shape)\n",
    "print('Shape of y_train', y_train.shape)\n",
    "print('Shape of y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Numerical Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorizations\n",
      "Shape of X_train_age_norm\n",
      "(8418, 1) (8418,)\n",
      "Shape of X_test_age_norm\n",
      "(2105, 1) (2105,)\n",
      "====================================================================================================\n",
      "After vectorizations\n",
      "Shape of X_train_balance_norm\n",
      "(8418, 1) (8418,)\n",
      "Shape of X_test_balance_norm\n",
      "(2105, 1) (2105,)\n",
      "====================================================================================================\n",
      "After vectorizations\n",
      "Shape of X_train_duration_norm\n",
      "(8418, 1) (8418,)\n",
      "Shape of X_test_duration_norm\n",
      "(2105, 1) (2105,)\n",
      "====================================================================================================\n",
      "After vectorizations\n",
      "Shape of X_train_campaign_norm\n",
      "(8418, 1) (8418,)\n",
      "Shape of X_test_campaign_norm\n",
      "(2105, 1) (2105,)\n",
      "====================================================================================================\n",
      "After vectorizations\n",
      "Shape of X_train_pdays_norm\n",
      "(8418, 1) (8418,)\n",
      "Shape of X_test_pdays_norm\n",
      "(2105, 1) (2105,)\n",
      "====================================================================================================\n",
      "After vectorizations\n",
      "Shape of X_train_previous_norm\n",
      "(8418, 1) (8418,)\n",
      "Shape of X_test_previous_norm\n",
      "(2105, 1) (2105,)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "var_dict={}\n",
    "from sklearn.preprocessing import Normalizer\n",
    "Numerical_features=['age','balance','duration','campaign','pdays','previous']\n",
    "# There are few ways to do it some of them have been listed in the loop.\n",
    "for feature in Numerical_features:\n",
    "    normalizer = Normalizer()\n",
    "    normalizer.fit(X_train[feature].values.reshape(-1,1))\n",
    "\n",
    "\n",
    "#     \"X_train_%s_norm\"%(feature)=normalizer.transform(X_train[feature].values.reshape(-1,1))\n",
    "#     global exec('X_train_%s_norm'%(feature))\n",
    "#     globals()[\"X_train_{feature}_norm\"]=normalizer.transform(X_train[feature].values.reshape(-1,1))\n",
    "#     global \"X_train_{}_norm\".format(feature)\n",
    "#     global exec ('X_test_{feature}_norm')\n",
    "    var_dict[\"X_train_{}_norm\".format(feature)]= normalizer.transform(X_train[feature].values.reshape(-1,1))\n",
    "#     X_test_pdays_norm = normalizer.transform(X_test[feature].values.reshape(-1,1))\n",
    "#     globals()[\"X_test_{feature}_norm\"]= normalizer.transform(X_test[feature].values.reshape(-1,1))\n",
    "    var_dict[\"X_test_{}_norm\".format(feature)]= normalizer.transform(X_test[feature].values.reshape(-1,1))\n",
    "#     exec(f'X_train_{feature}_norm') = var_dict[\"X_train_{}_norm\".format(feature)]\n",
    "#     exec(f'X_test_{feature}_norm') = var_dict[\"X_test_{}_norm\".format(feature)]\n",
    "    print(\"After vectorizations\")\n",
    "#     print(X_train_pdays_norm.shape, y_train.shape)\n",
    "    print(\"Shape of X_train_{}_norm\".format(feature))\n",
    "    print(var_dict[\"X_train_%s_norm\"%(feature)].shape, y_train.shape)\n",
    "#     print(X_test_pdays_norm.shape, y_test.shape)\n",
    "    print(\"Shape of X_test_{}_norm\".format(feature))\n",
    "    print(var_dict[\"X_test_%s_norm\"%(feature)].shape, y_test.shape)\n",
    "    print(\"=\"*100)  \n",
    "# X_train_balance_age.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_dict['X_train_previous_norm'].shape\n",
    "X_train_age_norm = var_dict['X_train_age_norm']\n",
    "X_test_age_norm = var_dict['X_test_age_norm']\n",
    "X_train_balance_norm = var_dict['X_train_balance_norm']\n",
    "X_test_balance_norm = var_dict['X_test_balance_norm']\n",
    "X_train_duration_norm = var_dict['X_train_duration_norm']\n",
    "X_test_duration_norm = var_dict['X_test_duration_norm']\n",
    "X_train_campaign_norm = var_dict['X_train_campaign_norm']\n",
    "X_test_campaign_norm = var_dict['X_test_campaign_norm']\n",
    "X_train_pdays_norm = var_dict['X_train_pdays_norm']\n",
    "X_test_pdays_norm = var_dict['X_test_pdays_norm']\n",
    "X_train_previous_norm = var_dict['X_train_previous_norm']\n",
    "X_test_previous_norm = var_dict['X_test_previous_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_previous_norm:  (8418, 1)\n",
      "X_test_previous_norm:  (2105, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X_train_previous_norm: ',X_train_previous_norm.shape)\n",
    "print('X_test_previous_norm: ',X_test_previous_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train_job:  (8418, 1)\n",
      "shape of X_test_job:  (2105, 1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "shape of X_train_marital:  (8418, 1)\n",
      "shape of X_test_marital:  (2105, 1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "shape of X_train_education:  (8418, 1)\n",
      "shape of X_test_education:  (2105, 1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "shape of X_train_default:  (8418, 1)\n",
      "shape of X_test_default:  (2105, 1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "shape of X_train_housing:  (8418, 1)\n",
      "shape of X_test_housing:  (2105, 1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "shape of X_train_loan:  (8418, 1)\n",
      "shape of X_test_loan:  (2105, 1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "shape of X_train_contact:  (8418, 1)\n",
      "shape of X_test_contact:  (2105, 1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "shape of X_train_day:  (8418, 1)\n",
      "shape of X_test_day:  (2105, 1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "shape of X_train_month:  (8418, 1)\n",
      "shape of X_test_month:  (2105, 1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "shape of X_train_poutcome:  (8418, 1)\n",
      "shape of X_test_poutcome:  (2105, 1)\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# X_train_age= X_train['age'].values.reshape(-1,1)\n",
    "# X_test_age= X_test['age'].values.reshape(-1,1)\n",
    "# print('shape of X_train_age: ',X_train_age.shape)\n",
    "# print('shape of X_test_age: ',X_test_age.shape)\n",
    "# print(\"-\"*100)\n",
    "# X_train_job= X_train['job'].values.reshape(-1,1)\n",
    "# X_test_job= X_test['job'].values.reshape(-1,1)\n",
    "# print('shape of X_train_job: ',X_train_job.shape)\n",
    "# print('shape of X_test_job: ',X_test_job.shape)\n",
    "# print(\"-\"*100)\n",
    "# X_train_marital= X_train['marital'].values.reshape(-1,1)\n",
    "# X_test_marital= X_test['marital'].values.reshape(-1,1)\n",
    "# print('shape of X_train_marital: ',X_train_marital.shape)\n",
    "# print('shape of X_test_marital: ',X_test_marital.shape)\n",
    "# print(\"-\"*100)\n",
    "# X_train_education= X_train['education'].values.reshape(-1,1)\n",
    "# X_test_education= X_test['education'].values.reshape(-1,1)\n",
    "# print('shape of X_train_education: ',X_train_education.shape)\n",
    "# print('shape of X_test_education: ',X_test_education.shape)\n",
    "# print(\"-\"*100)\n",
    "# X_train_default= X_train['default'].values.reshape(-1,1)\n",
    "# X_test_default= X_test['default'].values.reshape(-1,1)\n",
    "# print('shape of X_train_default: ',X_train_default.shape)\n",
    "# print('shape of X_test_default: ',X_test_default.shape)\n",
    "# print(\"-\"*100)\n",
    "# X_train_housing= X_train['housing'].values.reshape(-1,1)\n",
    "# X_test_housing= X_test['housing'].values.reshape(-1,1)\n",
    "# print('shape of X_train_housing: ',X_train_housing.shape)\n",
    "# print('shape of X_test_housing: ',X_test_housing.shape)\n",
    "# print(\"-\"*100)\n",
    "# X_train_loan= X_train['loan'].values.reshape(-1,1)\n",
    "# X_test_loan= X_test['default'].values.reshape(-1,1)\n",
    "# print('shape of X_train_loan: ',X_train_loan.shape)\n",
    "# print('shape of X_test_loan: ',X_test_loan.shape)\n",
    "# print(\"-\"*100)\n",
    "# X_train_contact= X_train['contact'].values.reshape(-1,1)\n",
    "# X_test_contact= X_test['contact'].values.reshape(-1,1)\n",
    "# print('shape of X_train_contact: ',X_train_contact.shape)\n",
    "# print('shape of X_test_contact: ',X_test_contact.shape)\n",
    "# print(\"-\"*100)\n",
    "# X_train_contact= X_train['contact'].values.reshape(-1,1)\n",
    "# X_test_contact= X_test['contact'].values.reshape(-1,1)\n",
    "# print('shape of X_train_contact: ',X_train_contact.shape)\n",
    "# print('shape of X_test_contact: ',X_test_contact.shape)\n",
    "# print(\"-\"*100)\n",
    "\n",
    "var_dict1={}\n",
    "label_features=['job','marital','education','default','housing','loan','contact','day','month','poutcome']\n",
    "for feature in label_features:\n",
    "    var_dict1[\"X_train_%s\"%(feature)]= X_train[feature].values.reshape(-1,1)\n",
    "    var_dict1[\"X_test_%s\"%(feature)]= X_test[feature].values.reshape(-1,1)\n",
    "    print('shape of X_train_{}: '.format(feature),(var_dict1[\"X_train_%s\"%(feature)]).shape)\n",
    "    print('shape of X_test_{}: '.format(feature),var_dict1[\"X_test_%s\"%(feature)].shape)\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_job (8418, 1)\n",
      "Shape of X_test_job (2105, 1)\n",
      "Shape of X_train_marital (8418, 1)\n",
      "Shape of X_test_marital (2105, 1)\n",
      "Shape of X_train_education (8418, 1)\n",
      "Shape of X_test_education (2105, 1)\n",
      "Shape of X_train_default (8418, 1)\n",
      "Shape of X_test_default (2105, 1)\n",
      "Shape of X_train_housing (8418, 1)\n",
      "Shape of X_test_housing (2105, 1)\n",
      "Shape of X_train_loan (8418, 1)\n",
      "Shape of X_test_loan (2105, 1)\n",
      "Shape of X_train_contact (8418, 1)\n",
      "Shape of X_test_contact (2105, 1)\n",
      "Shape of X_train_day (8418, 1)\n",
      "Shape of X_test_day (2105, 1)\n",
      "Shape of X_train_month (8418, 1)\n",
      "Shape of X_test_month (2105, 1)\n",
      "Shape of X_train_poutcome (8418, 1)\n",
      "Shape of X_test_poutcome (2105, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_job = var_dict1['X_train_job']\n",
    "print('Shape of X_train_job',X_train_job.shape)\n",
    "X_test_job = var_dict1['X_test_job']\n",
    "print('Shape of X_test_job',X_test_job.shape)\n",
    "X_train_marital = var_dict1['X_train_marital']\n",
    "print('Shape of X_train_marital',X_train_marital.shape)\n",
    "X_test_marital = var_dict1['X_test_marital']\n",
    "print('Shape of X_test_marital',X_test_marital.shape)\n",
    "X_train_education = var_dict1['X_train_education']\n",
    "print('Shape of X_train_education',X_train_education.shape)\n",
    "X_test_education = var_dict1['X_test_education']\n",
    "print('Shape of X_test_education',X_test_education.shape)\n",
    "X_train_default = var_dict1['X_train_default']\n",
    "print('Shape of X_train_default',X_train_default.shape)\n",
    "X_test_default = var_dict1['X_test_default']\n",
    "print('Shape of X_test_default',X_test_default.shape)\n",
    "X_train_housing = var_dict1['X_train_housing']\n",
    "print('Shape of X_train_housing',X_train_housing.shape)\n",
    "X_test_housing = var_dict1['X_test_housing']\n",
    "print('Shape of X_test_housing',X_test_housing.shape)\n",
    "X_train_loan = var_dict1['X_train_loan']\n",
    "print('Shape of X_train_loan',X_train_loan.shape)\n",
    "X_test_loan = var_dict1['X_test_loan']\n",
    "print('Shape of X_test_loan',X_test_loan.shape)\n",
    "X_train_contact = var_dict1['X_train_contact']\n",
    "print('Shape of X_train_contact',X_train_contact.shape)\n",
    "X_test_contact = var_dict1['X_test_contact']\n",
    "print('Shape of X_test_contact',X_test_contact.shape)\n",
    "X_train_day = var_dict1['X_train_day']\n",
    "print('Shape of X_train_day',X_train_day.shape)\n",
    "X_test_day = var_dict1['X_test_day']\n",
    "print('Shape of X_test_day',X_test_day.shape)\n",
    "X_train_month = var_dict1['X_train_month']\n",
    "print('Shape of X_train_month',X_train_month.shape)\n",
    "X_test_month = var_dict1['X_test_month']\n",
    "print('Shape of X_test_month',X_test_month.shape)\n",
    "X_train_poutcome = var_dict1['X_train_poutcome']\n",
    "print('Shape of X_train_poutcome',X_train_poutcome.shape)\n",
    "X_test_poutcome = var_dict1['X_test_poutcome']\n",
    "print('Shape of X_test_poutcome',X_test_poutcome.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_job = X_train_job.reshape(-1,1)\n",
    "X_test_job = X_test_job.reshape(-1,1)\n",
    "X_train_marital = X_train_marital.reshape(-1,1)\n",
    "X_test_marital = X_test_marital.reshape(-1,1)\n",
    "X_train_education = X_train_education.reshape(-1,1)\n",
    "X_test_education = X_test_education.reshape(-1,1)\n",
    "X_train_default = X_train_default.reshape(-1,1)\n",
    "X_test_default = X_test_default.reshape(-1,1)\n",
    "X_train_housing = X_train_housing.reshape(-1,1)\n",
    "X_test_housing = X_test_housing.reshape(-1,1)\n",
    "X_train_loan = X_train_loan.reshape(-1,1)\n",
    "X_test_loan = X_test_loan.reshape(-1,1)\n",
    "X_train_contact = X_train_contact.reshape(-1,1)\n",
    "X_test_contact = X_test_contact.reshape(-1,1)\n",
    "X_train_day = X_train_day.reshape(-1,1)\n",
    "X_test_day = X_test_day.reshape(-1,1)\n",
    "X_train_month = X_train_month.reshape(-1,1)\n",
    "X_train_poutcome = X_train_poutcome.reshape(-1,1)\n",
    "X_test_poutcome = X_test_poutcome.reshape(-1,1)\n",
    "X_train_age_norm = X_train_age_norm.reshape(-1,1)\n",
    "X_test_age_norm = X_test_age_norm.reshape(-1,1)\n",
    "X_train_balance_norm = X_train_balance_norm.reshape(-1,1)\n",
    "X_test_balance_norm = X_test_balance_norm.reshape(-1,1)\n",
    "X_train_duration_norm = X_train_duration_norm.reshape(-1,1)\n",
    "X_test_duration_norm = X_test_duration_norm.reshape(-1,1)\n",
    "X_train_campaign_norm = X_train_campaign_norm.reshape(-1,1)\n",
    "X_test_campaign_norm = X_test_campaign_norm.reshape(-1,1)\n",
    "X_train_pdays_norm = X_train_pdays_norm.reshape(-1,1)\n",
    "X_test_pdays_norm = X_test_pdays_norm.reshape(-1,1)\n",
    "X_train_previous_norm = X_train_previous_norm.reshape(-1,1)\n",
    "X_test_previous_norm = X_test_previous_norm.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-300-26ac69d7593e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train_job\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "X_train_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating label Encoded and normalized features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Data matrix\n",
      "(8418, 16) (8418,)\n",
      "(2105, 16) (2105,)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# from scipy.sparse import hstack\n",
    "from numpy import hstack\n",
    "from scipy.sparse import csr_matrix\n",
    "X_train = csr_matrix(hstack((X_train_age_norm, X_train_job, X_train_marital, X_train_education, X_train_default, X_train_balance_norm, X_train_housing, X_train_loan, X_train_contact, X_train_day, X_train_month, X_train_duration_norm, X_train_campaign_norm, X_train_pdays_norm, X_train_previous_norm,X_train_poutcome)))\n",
    "X_test = csr_matrix(hstack((X_test_age_norm, X_test_job, X_test_marital, X_test_education, X_test_default, X_test_balance_norm, X_test_housing, X_test_loan, X_test_contact, X_test_day, X_test_month, X_test_duration_norm, X_test_campaign_norm, X_test_pdays_norm, X_test_previous_norm,X_test_poutcome)))\n",
    "\n",
    "print(\"Final Data matrix\")\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning model for classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 21.544346900318867, 'penalty': 'l2'}\n",
      "accuracy : 0.7656221668017656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# let's create models through trying out multiple parameters and finding out the best model with the best parameters. \n",
    "# For this we will be using gridSearchCV technique.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "parameters = {\"C\":np.logspace(-7,3,7),\"penalty\":['l1','l2']}\n",
    "log_reg=LogisticRegression()\n",
    "clf=GridSearchCV(log_reg, parameters, cv=10)\n",
    "clf.fit(X_train,y_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",clf.best_params_)\n",
    "print(\"accuracy :\",clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.7724465558194774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.85      0.80      1119\n",
      "           1       0.80      0.69      0.74       986\n",
      "\n",
      "    accuracy                           0.77      2105\n",
      "   macro avg       0.78      0.77      0.77      2105\n",
      "weighted avg       0.78      0.77      0.77      2105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "clf=log_reg=LogisticRegression(C=21.544346900318867, penalty= 'l2', solver='lbfgs',max_iter= 500)\n",
    "clf.fit(X_train,y_train)\n",
    "print(\"score\",clf.score(X_test,y_test))\n",
    "print(metrics.classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.658, test=0.658), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.657, test=0.667), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.658, test=0.662), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.656, test=0.675), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.659, test=0.652), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.659, test=0.654), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.657, test=0.670), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.660, test=0.639), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.658, test=0.658), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.659, test=0.648), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.658, test=0.658), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.657, test=0.667), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.658, test=0.662), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.656, test=0.675), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.659, test=0.652), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.659, test=0.654), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.657, test=0.670), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.660, test=0.639), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.658, test=0.658), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.659, test=0.648), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.658, test=0.658), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.657, test=0.667), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.658, test=0.662), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.656, test=0.675), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.659, test=0.652), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.659, test=0.654), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.657, test=0.670), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.660, test=0.639), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.658, test=0.658), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.659, test=0.648), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.658, test=0.658), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.657, test=0.667), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.658, test=0.662), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.656, test=0.675), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.659, test=0.652), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.659, test=0.654), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.657, test=0.670), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.660, test=0.639), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.658, test=0.658), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.659, test=0.648), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.785, test=0.774), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.784, test=0.779), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.785, test=0.768), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.784, test=0.786), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.783, test=0.789), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.784, test=0.779), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.782, test=0.796), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.783, test=0.789), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.786, test=0.766), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.782, test=0.798), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.785, test=0.774), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.784, test=0.779), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.785, test=0.768), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.784, test=0.786), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.783, test=0.789), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.784, test=0.779), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.782, test=0.796), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.783, test=0.789), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.786, test=0.766), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.782, test=0.798), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.784, test=0.773), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.783, test=0.778), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.784, test=0.771), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.782, test=0.785), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.782, test=0.789), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.783, test=0.778), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.781, test=0.796), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.782, test=0.787), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.784, test=0.765), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.781, test=0.797), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.783, test=0.776), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.783, test=0.778), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.784, test=0.771), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.782, test=0.785), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.782, test=0.789), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.783, test=0.780), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.781, test=0.796), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.782, test=0.787), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.784, test=0.765), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.781, test=0.797), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.839, test=0.790), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.831, test=0.806), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.838, test=0.791), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.835, test=0.828), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.839, test=0.811), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.833, test=0.808), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.833, test=0.811), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.836, test=0.816), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.836, test=0.826), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.843, test=0.818), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.838, test=0.787), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.828, test=0.806), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.835, test=0.791), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.833, test=0.824), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.837, test=0.810), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.831, test=0.809), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.831, test=0.814), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.834, test=0.817), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.834, test=0.828), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.840, test=0.820), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.825, test=0.793), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.820, test=0.806), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.824, test=0.790), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.822, test=0.823), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.827, test=0.822), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.822, test=0.808), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.821, test=0.821), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.823, test=0.822), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.822, test=0.823), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.825, test=0.824), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.803, test=0.783), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.793, test=0.790), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.801, test=0.779), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.808, test=0.812), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.808, test=0.806), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.805, test=0.800), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.803, test=0.815), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.806, test=0.805), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.804, test=0.811), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.801, test=0.810), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.929, test=0.766), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.926, test=0.767), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.930, test=0.770), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.927, test=0.776), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.927, test=0.776), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.926, test=0.786), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.928, test=0.779), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.927, test=0.783), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.929, test=0.767), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.929, test=0.765), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.899, test=0.774), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.898, test=0.802), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.898, test=0.777), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.899, test=0.800), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.897, test=0.791), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.898, test=0.809), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.902, test=0.783), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.898, test=0.795), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.901, test=0.792), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.899, test=0.799), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.840, test=0.808), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.830, test=0.819), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.833, test=0.781), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.834, test=0.829), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.839, test=0.827), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.835, test=0.812), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.837, test=0.829), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.837, test=0.830), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.835, test=0.825), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.835, test=0.822), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.803, test=0.783), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.793, test=0.790), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.801, test=0.779), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.808, test=0.812), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.808, test=0.806), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.805, test=0.800), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.803, test=0.815), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.806, test=0.805), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.804, test=0.811), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.801, test=0.810), total=   0.0s\n",
      "BEST DEPTH:  50 BEST MIN SAMPLE SPLITS:  100  BEST SCORE:  0.8182478442980164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:    4.4s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier(class_weight ='balanced')\n",
    "parameters = {'max_depth':[1, 5, 10, 50],'min_samples_split':[5, 10, 100, 500]}\n",
    "clf = GridSearchCV(dt_clf, parameters, cv= 10, scoring='accuracy', verbose=10,return_train_score=True)\n",
    "clf.fit(X_train,y_train)\n",
    "train_score= clf.cv_results_['mean_train_score']\n",
    "train_score= clf.cv_results_['std_train_score']\n",
    "cv_score = clf.cv_results_['mean_test_score']\n",
    "cv_score = clf.cv_results_['std_test_score']\n",
    "bestDepth=clf.best_params_['max_depth']\n",
    "bestScore=clf.best_score_\n",
    "print(\"BEST DEPTH: \",clf.best_params_['max_depth'],\"BEST MIN SAMPLE SPLITS: \",clf.best_params_['min_samples_split'],\" BEST SCORE: \",clf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.8199524940617577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1119\n",
      "           1       0.81      0.81      0.81       986\n",
      "\n",
      "    accuracy                           0.82      2105\n",
      "   macro avg       0.82      0.82      0.82      2105\n",
      "weighted avg       0.82      0.82      0.82      2105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"score\",clf.score(X_test,y_test))\n",
    "print(metrics.classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.733, test=0.747), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.735, test=0.723), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.743, test=0.746), total=   0.3s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.744, test=0.747), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.737, test=0.714), total=   0.3s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.744, test=0.738), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    1.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.742, test=0.753), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    2.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.742, test=0.752), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    2.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.745, test=0.723), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    2.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.736, test=0.741), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.733, test=0.747), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.735, test=0.723), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.743, test=0.746), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.744, test=0.747), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.737, test=0.714), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.744, test=0.738), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.742, test=0.753), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.742, test=0.752), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.745, test=0.723), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.736, test=0.741), total=   0.3s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.733, test=0.747), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.735, test=0.723), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.743, test=0.746), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.744, test=0.747), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.737, test=0.714), total=   0.3s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.744, test=0.738), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.742, test=0.753), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.742, test=0.752), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.745, test=0.723), total=   0.3s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.736, test=0.741), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.733, test=0.747), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.735, test=0.723), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.743, test=0.746), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.744, test=0.747), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.737, test=0.714), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.744, test=0.738), total=   0.5s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.742, test=0.753), total=   0.3s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.742, test=0.752), total=   0.3s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.745, test=0.723), total=   0.3s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.736, test=0.741), total=   0.2s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.786, test=0.783), total=   0.5s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.789, test=0.784), total=   0.5s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.790, test=0.772), total=   0.5s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.787, test=0.784), total=   0.4s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.787, test=0.787), total=   0.4s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.786, test=0.787), total=   0.4s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.789, test=0.792), total=   0.4s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.785, test=0.793), total=   0.4s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.784, test=0.760), total=   0.6s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.780, test=0.786), total=   0.5s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.786, test=0.783), total=   0.6s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.788, test=0.785), total=   0.6s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.789, test=0.772), total=   0.5s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.787, test=0.785), total=   0.4s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.785, test=0.783), total=   0.4s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.786, test=0.787), total=   0.5s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.789, test=0.792), total=   0.6s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.784, test=0.792), total=   0.5s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.784, test=0.760), total=   0.5s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.780, test=0.790), total=   0.5s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.786, test=0.783), total=   0.4s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.788, test=0.781), total=   0.5s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.790, test=0.772), total=   0.4s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.789, test=0.784), total=   0.5s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.787, test=0.791), total=   0.5s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.788, test=0.786), total=   0.5s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.788, test=0.791), total=   0.5s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.786, test=0.796), total=   0.4s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.785, test=0.756), total=   0.5s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.779, test=0.790), total=   0.4s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.783, test=0.783), total=   0.4s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.783, test=0.780), total=   0.5s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.789, test=0.772), total=   0.4s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.787, test=0.783), total=   0.4s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.783, test=0.780), total=   0.4s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.787, test=0.789), total=   0.4s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.788, test=0.792), total=   0.4s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.787, test=0.797), total=   0.4s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.787, test=0.762), total=   0.4s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.779, test=0.788), total=   0.4s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.838, test=0.812), total=   1.2s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.835, test=0.809), total=   1.3s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.839, test=0.798), total=   1.3s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.833, test=0.818), total=   1.3s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.834, test=0.819), total=   1.5s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.836, test=0.821), total=   1.4s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.834, test=0.823), total=   2.2s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.837, test=0.822), total=   1.4s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.834, test=0.809), total=   1.2s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.836, test=0.829), total=   1.7s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.835, test=0.811), total=   1.9s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.833, test=0.817), total=   1.3s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.836, test=0.805), total=   1.3s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.833, test=0.814), total=   1.2s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.830, test=0.814), total=   1.5s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.832, test=0.817), total=   1.3s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.829, test=0.823), total=   1.3s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.832, test=0.819), total=   1.3s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.831, test=0.805), total=   1.4s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.831, test=0.828), total=   1.4s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.821, test=0.812), total=   1.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.819, test=0.811), total=   0.9s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.823, test=0.797), total=   1.1s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.819, test=0.818), total=   1.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.818, test=0.816), total=   0.9s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.820, test=0.814), total=   0.9s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.819, test=0.815), total=   0.8s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.820, test=0.818), total=   0.9s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.818, test=0.799), total=   0.9s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.818, test=0.823), total=   0.9s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.805, test=0.800), total=   0.7s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.804, test=0.804), total=   0.6s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.809, test=0.789), total=   0.5s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.806, test=0.809), total=   0.5s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.803, test=0.810), total=   0.5s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.807, test=0.810), total=   0.5s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.807, test=0.804), total=   0.5s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.806, test=0.809), total=   0.5s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.803, test=0.791), total=   0.4s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.803, test=0.815), total=   0.5s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.932, test=0.808), total=   2.5s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.930, test=0.830), total=   2.6s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.930, test=0.812), total=   2.6s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.930, test=0.830), total=   2.6s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.930, test=0.816), total=   2.6s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.928, test=0.833), total=   2.5s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.930, test=0.811), total=   2.6s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.930, test=0.818), total=   2.6s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.929, test=0.823), total=   2.7s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.929, test=0.811), total=   3.1s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.899, test=0.819), total=   2.6s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.896, test=0.835), total=   2.4s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.897, test=0.802), total=   2.5s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.896, test=0.833), total=   2.7s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.898, test=0.830), total=   2.6s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.896, test=0.838), total=   2.4s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.899, test=0.825), total=   2.8s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.897, test=0.831), total=   3.4s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.896, test=0.824), total=   2.9s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.896, test=0.822), total=   2.8s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.830, test=0.809), total=   1.5s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.825, test=0.816), total=   1.2s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.829, test=0.792), total=   1.1s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.826, test=0.818), total=   1.2s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.827, test=0.825), total=   1.3s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.825, test=0.824), total=   1.2s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.828, test=0.828), total=   1.3s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.824, test=0.817), total=   1.1s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.824, test=0.806), total=   1.2s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.823, test=0.822), total=   1.0s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.805, test=0.800), total=   0.5s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.803, test=0.802), total=   0.4s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.811, test=0.790), total=   0.5s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.806, test=0.808), total=   0.5s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.803, test=0.811), total=   0.5s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.807, test=0.809), total=   0.5s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.807, test=0.803), total=   0.5s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.806, test=0.810), total=   0.5s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.804, test=0.794), total=   0.4s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.803, test=0.813), total=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST DEPTH:  50 BEST min_samples_split:  10  BEST SCORE:  0.8259674180437834\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf=RandomForestClassifier(random_state=51)\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "clf_rf = GridSearchCV(rf_clf, parameters, cv= 10, scoring='accuracy', verbose=10,return_train_score=True)\n",
    "clf_rf.fit(X_train,y_train)\n",
    "train_score= clf_rf.cv_results_['mean_train_score']\n",
    "train_score= clf_rf.cv_results_['std_train_score']\n",
    "cv_score = clf_rf.cv_results_['mean_test_score']\n",
    "cv_score = clf_rf.cv_results_['std_test_score']\n",
    "bestDepth=clf_rf.best_params_['max_depth']\n",
    "bestScore=clf_rf.best_score_\n",
    "print(\"BEST DEPTH: \",clf_rf.best_params_['max_depth'],\"BEST min_samples_split: \",clf_rf.best_params_['min_samples_split'],\" BEST SCORE: \",clf_rf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.8266033254156769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84      1119\n",
      "           1       0.83      0.80      0.81       986\n",
      "\n",
      "    accuracy                           0.83      2105\n",
      "   macro avg       0.83      0.82      0.83      2105\n",
      "weighted avg       0.83      0.83      0.83      2105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"score\",clf_rf.score(X_test,y_test))\n",
    "print(metrics.classification_report(y_test, clf_rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rf_clf1.pkl']"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.geeksforgeeks.org/saving-a-machine-learning-model/\n",
    "from sklearn.externals import joblib\n",
    " \n",
    "# Save the model as a pickle in a file\n",
    "joblib.dump(clf_rf, 'rf_clf1.pkl')\n",
    "\n",
    "# the following lines of code will load back and predict using the model\n",
    "# # Load the model from the file\n",
    "# clf_rf_from_joblib = joblib.load('rf_clf1.pkl')\n",
    " \n",
    "# # Use the loaded model to make predictions\n",
    "# clf_rf_from_joblib.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XgBoost Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[06:34:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:34:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.777, test=0.780), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[06:34:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:34:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.777, test=0.774), total=   1.0s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[06:34:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:34:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.779, test=0.759), total=   1.1s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[06:34:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:34:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.778, test=0.772), total=   1.3s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[06:34:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:34:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.778, test=0.768), total=   1.0s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[06:34:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:34:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.777, test=0.786), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[06:34:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:34:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    6.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.778, test=0.779), total=   1.0s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[06:34:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:34:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    7.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.778, test=0.778), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[06:34:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:34:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    8.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.777, test=0.768), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[06:34:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:34:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    9.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.775, test=0.798), total=   1.0s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[06:34:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:34:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.777, test=0.780), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[06:34:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:34:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.777, test=0.774), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[06:34:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:34:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.779, test=0.759), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[06:34:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:34:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.778, test=0.772), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[06:34:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:34:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.778, test=0.768), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[06:34:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:34:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.777, test=0.786), total=   1.0s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[06:35:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.778, test=0.779), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[06:35:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.778, test=0.778), total=   1.0s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[06:35:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.777, test=0.768), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[06:35:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.775, test=0.798), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[06:35:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.777, test=0.780), total=   1.2s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[06:35:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.777, test=0.774), total=   1.1s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[06:35:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.779, test=0.759), total=   1.1s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[06:35:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.778, test=0.772), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[06:35:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.778, test=0.768), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[06:35:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.777, test=0.786), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[06:35:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.778, test=0.779), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[06:35:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.778, test=0.778), total=   1.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[06:35:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.777, test=0.768), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[06:35:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.775, test=0.798), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[06:35:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.777, test=0.780), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[06:35:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.777, test=0.774), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[06:35:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.779, test=0.759), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[06:35:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.778, test=0.772), total=   1.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[06:35:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.778, test=0.768), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[06:35:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.777, test=0.786), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[06:35:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.778, test=0.779), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[06:35:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.778, test=0.778), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[06:35:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.777, test=0.768), total=   1.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[06:35:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.775, test=0.798), total=   0.9s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[06:35:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.859, test=0.822), total=   2.7s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[06:35:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.856, test=0.841), total=   2.8s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[06:35:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.859, test=0.823), total=   2.7s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[06:35:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.856, test=0.846), total=   3.1s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[06:35:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.858, test=0.835), total=   3.2s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[06:35:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.858, test=0.842), total=   3.1s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[06:35:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.857, test=0.837), total=   3.0s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[06:35:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.857, test=0.838), total=   2.7s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[06:35:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.857, test=0.843), total=   2.9s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[06:35:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.857, test=0.847), total=   2.7s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[06:35:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.859, test=0.822), total=   2.8s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[06:35:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:35:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.856, test=0.841), total=   2.7s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[06:36:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:36:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.859, test=0.823), total=   2.8s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[06:36:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:36:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.856, test=0.846), total=   2.7s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[06:36:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:36:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.858, test=0.835), total=   3.3s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[06:36:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:36:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.858, test=0.842), total=   2.9s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[06:36:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:36:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.857, test=0.837), total=   3.0s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[06:36:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:36:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.857, test=0.838), total=   2.7s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[06:36:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:36:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.857, test=0.843), total=   2.8s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[06:36:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:36:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.857, test=0.847), total=   2.7s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[06:36:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:36:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.859, test=0.822), total=   2.8s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[06:36:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:36:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.856, test=0.841), total=   2.8s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[06:36:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:36:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.859, test=0.823), total=   2.7s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[06:36:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:36:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.856, test=0.846), total=   2.9s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[06:36:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:36:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.858, test=0.835), total=   3.5s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[06:36:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:36:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.858, test=0.842), total=   3.2s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[06:36:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:36:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.857, test=0.837), total=   2.8s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[06:36:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:36:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.857, test=0.838), total=   3.1s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[06:36:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:36:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.857, test=0.843), total=   3.1s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[06:36:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:36:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.857, test=0.847), total=   2.9s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[06:36:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:36:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.859, test=0.822), total=   2.9s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[06:36:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:36:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.856, test=0.841), total=   2.8s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[06:37:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:37:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.859, test=0.823), total=   2.9s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[06:37:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:37:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.856, test=0.846), total=   2.7s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[06:37:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:37:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.858, test=0.835), total=   3.5s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[06:37:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:37:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.858, test=0.842), total=   3.1s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[06:37:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:37:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.857, test=0.837), total=   2.7s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[06:37:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:37:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.857, test=0.838), total=   2.9s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[06:37:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:37:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.857, test=0.843), total=   2.9s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[06:37:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:37:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.857, test=0.847), total=   2.8s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[06:37:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:37:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.917, test=0.819), total=   6.2s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[06:37:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:37:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.919, test=0.828), total=   6.2s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[06:37:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:37:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.918, test=0.806), total=   7.1s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[06:37:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:37:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.917, test=0.848), total=   6.4s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[06:37:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:37:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.916, test=0.823), total=   6.6s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[06:38:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:38:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.917, test=0.844), total=   6.4s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[06:38:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:38:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.920, test=0.824), total=   6.8s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[06:38:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:38:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.920, test=0.834), total=   6.5s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[06:38:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:38:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.922, test=0.837), total=   6.5s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[06:38:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:38:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.919, test=0.828), total=   6.3s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[06:38:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:38:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.917, test=0.819), total=   6.3s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[06:38:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:38:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.919, test=0.828), total=   7.1s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[06:38:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:38:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.918, test=0.806), total=   6.5s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[06:38:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:38:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.917, test=0.848), total=   6.9s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[06:39:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:39:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.916, test=0.823), total=   6.4s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[06:39:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:39:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.917, test=0.844), total=   7.4s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[06:39:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:39:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.920, test=0.824), total=   6.7s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[06:39:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:39:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.920, test=0.834), total=   6.5s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[06:39:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:39:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.922, test=0.837), total=   6.3s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[06:39:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:39:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.919, test=0.828), total=   6.3s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[06:39:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:39:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.917, test=0.819), total=   7.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[06:39:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:39:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.919, test=0.828), total=   6.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[06:39:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:39:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.918, test=0.806), total=   6.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[06:40:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:40:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.917, test=0.848), total=   6.4s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[06:40:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:40:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.916, test=0.823), total=   5.9s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[06:40:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:40:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.917, test=0.844), total=   6.8s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[06:40:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:40:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.920, test=0.824), total=   6.1s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[06:40:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:40:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.920, test=0.834), total=   6.2s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[06:40:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:40:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.922, test=0.837), total=   6.1s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[06:40:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:40:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.919, test=0.828), total=   6.2s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[06:40:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:40:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.917, test=0.819), total=   6.3s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[06:40:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:40:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.919, test=0.828), total=   6.0s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[06:41:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:41:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.918, test=0.806), total=   5.9s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[06:41:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:41:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.917, test=0.848), total=   6.4s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[06:41:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:41:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.916, test=0.823), total=   6.6s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[06:41:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:41:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.917, test=0.844), total=   6.1s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[06:41:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:41:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.920, test=0.824), total=   6.1s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[06:41:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:41:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.920, test=0.834), total=   6.0s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[06:41:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:41:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.922, test=0.837), total=   6.1s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[06:41:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:41:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.919, test=0.828), total=   6.9s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[06:41:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:41:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.964, test=0.809), total=  14.3s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[06:42:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:42:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.963, test=0.805), total=  15.0s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[06:42:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:42:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.964, test=0.795), total=  14.2s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[06:42:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:42:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.963, test=0.823), total=  14.7s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[06:42:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:42:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.962, test=0.803), total=  14.4s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[06:43:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:43:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.961, test=0.836), total=  14.3s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[06:43:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:43:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.963, test=0.815), total=  14.3s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[06:43:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:43:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.963, test=0.819), total=  13.9s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[06:43:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:43:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.963, test=0.804), total=  14.9s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[06:44:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:44:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.963, test=0.816), total=  14.2s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[06:44:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:44:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.964, test=0.809), total=  15.2s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[06:44:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:44:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.963, test=0.805), total=  13.8s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[06:44:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:44:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.964, test=0.795), total=  14.9s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[06:45:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:45:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.963, test=0.823), total=  14.2s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[06:45:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:45:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.962, test=0.803), total=  15.3s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[06:45:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:45:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.961, test=0.836), total=  13.9s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[06:45:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:45:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.963, test=0.815), total=  14.6s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[06:46:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:46:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.963, test=0.819), total=  13.9s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[06:46:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:46:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.963, test=0.804), total=  15.1s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[06:46:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:46:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.963, test=0.816), total=  14.5s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[06:46:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:46:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.964, test=0.809), total=  14.9s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[06:47:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:47:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.963, test=0.805), total=  14.0s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[06:47:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:47:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.964, test=0.795), total=  14.8s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[06:47:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:47:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.963, test=0.823), total=  14.5s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[06:47:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:47:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.962, test=0.803), total=  14.8s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[06:48:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:48:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.961, test=0.836), total=  14.0s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[06:48:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:48:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.963, test=0.815), total=  14.6s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[06:48:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:48:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.963, test=0.819), total=  14.5s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[06:48:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:48:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.963, test=0.804), total=  14.6s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[06:49:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:49:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.963, test=0.816), total=  14.8s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[06:49:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:49:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.964, test=0.809), total=  14.6s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[06:49:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:49:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.963, test=0.805), total=  14.3s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[06:49:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:49:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.964, test=0.795), total=  14.5s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[06:50:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:50:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.963, test=0.823), total=  14.7s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[06:50:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:50:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.962, test=0.803), total=  14.3s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[06:50:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:50:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.961, test=0.836), total=  14.7s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[06:50:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:50:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.963, test=0.815), total=  14.4s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[06:51:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:51:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.963, test=0.819), total=  14.9s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[06:51:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:51:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.963, test=0.804), total=  14.1s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[06:51:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:51:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.963, test=0.816), total=  15.8s\n",
      "[06:51:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[06:51:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed: 17.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST DEPTH:  5 BEST min_samples_split:  5  BEST SCORE:  0.8373740683102628\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "clf_xgb = GridSearchCV(xgb, parameters, cv= 10, scoring='accuracy', verbose=10,return_train_score=True)\n",
    "clf_xgb.fit(X_train,y_train)\n",
    "train_score= clf_xgb.cv_results_['mean_train_score']\n",
    "train_score= clf_xgb.cv_results_['std_train_score']\n",
    "cv_score = clf_xgb.cv_results_['mean_test_score']\n",
    "cv_score = clf_xgb.cv_results_['std_test_score']\n",
    "bestDepth=clf_xgb.best_params_['max_depth']\n",
    "bestScore=clf_xgb.best_score_\n",
    "print(\"BEST DEPTH: \",clf_xgb.best_params_['max_depth'],\"BEST min_samples_split: \",clf_xgb.best_params_['min_samples_split'],\" BEST SCORE: \",clf_xgb.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.8427553444180522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86      1119\n",
      "           1       0.87      0.78      0.82       986\n",
      "\n",
      "    accuracy                           0.84      2105\n",
      "   macro avg       0.85      0.84      0.84      2105\n",
      "weighted avg       0.85      0.84      0.84      2105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "joblib.dump(clf_xgb, 'clf_xgb.pkl')\n",
    "\n",
    "# the following lines of code will load back and predict using the model\n",
    "# clf_xgb_from_joblib = joblib.load('clf_xgb.pkl')\n",
    "# clf_xgb_from_joblib.predict(X_test)\n",
    "print(\"score\",clf_xgb.score(X_test,y_test))\n",
    "print(metrics.classification_report(y_test, clf_xgb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x15a140dbc48>"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ref: https://www.kaggle.com/agungor2/various-confusion-matrix-plots\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "data = confusion_matrix(y_test,  clf_xgb.predict(X_test))\n",
    "df_con = pd.DataFrame(data, columns=np.unique(y_test), index = np.unique(y_test))\n",
    "df_con.index.name = 'Actual'\n",
    "df_con.columns.name = 'Predicted'\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_con, cmap=\"Blues\", annot=True,annot_kws={\"size\": 15})# font size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
