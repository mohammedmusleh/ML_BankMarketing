{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset: https://www.kaggle.com/janiobachmann/bank-marketing-dataset/activity\n",
    "#Dataset Link: https://archive.ics.uci.edu/ml/datasets/Bank+Marketing\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ref: For graphs\n",
    "#https://datascienceplus.com/seaborn-categorical-plots-in-python/#:~:text=Seaborn%20is%20a%20Python%20visualization,routines%20from%20scipy%20and%20statsmodels.\n",
    "#for groupby both columns\n",
    "#https://stackoverflow.com/questions/45561118/how-i-can-apply-groupby-two-times-on-pandas-data-frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data =  (11162, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2343</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>45</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>1467</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>1270</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>1389</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2476</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>184</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>673</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         job  marital  education default  balance housing loan  contact  \\\n",
       "0   59      admin.  married  secondary      no     2343     yes   no  unknown   \n",
       "1   56      admin.  married  secondary      no       45      no   no  unknown   \n",
       "2   41  technician  married  secondary      no     1270     yes   no  unknown   \n",
       "3   55    services  married  secondary      no     2476     yes   no  unknown   \n",
       "4   54      admin.  married   tertiary      no      184      no   no  unknown   \n",
       "\n",
       "   day month  duration  campaign  pdays  previous poutcome deposit  \n",
       "0    5   may      1042         1     -1         0  unknown     yes  \n",
       "1    5   may      1467         1     -1         0  unknown     yes  \n",
       "2    5   may      1389         1     -1         0  unknown     yes  \n",
       "3    5   may       579         1     -1         0  unknown     yes  \n",
       "4    5   may       673         2     -1         0  unknown     yes  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('bank.csv')\n",
    "print('Shape of the data = ',data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     5873\n",
       "yes    5289\n",
       "Name: deposit, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The data is balanced over deposit or our target feature\n",
    "data['deposit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8324"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pdays is number of times customer is contacted in the compaign\n",
    "# number of customers not contacted in the compaign\n",
    "data['pdays'].value_counts()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['management', 'blue-collar', 'technician', 'admin.', 'services',\n",
       "       'retired', 'self-employed', 'student', 'unemployed', 'entrepreneur',\n",
       "       'housemaid', 'unknown'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['job'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# day says last day dd of the month contacted\n",
    "data['day'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688\n"
     ]
    }
   ],
   "source": [
    "neg=[x for x in data['balance'] if x<0]\n",
    "print(len(neg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels=data['job'].unique()\n",
    "# print(labels)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n",
    "sizes = [15, 30, 45, 10]\n",
    "explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig1, ax1 = plt.subplots()\n",
    "plt.figure(1, figsize=(40,20))\n",
    "ax1.pie(data['job'].value_counts(),labels=list(data['job'].value_counts().index),autopct='%1.1f%%')\n",
    "ax1.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>deposit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>admin.</th>\n",
       "      <td>1334</td>\n",
       "      <td>1334</td>\n",
       "      <td>1334</td>\n",
       "      <td>1334</td>\n",
       "      <td>1334</td>\n",
       "      <td>1334</td>\n",
       "      <td>1334</td>\n",
       "      <td>1334</td>\n",
       "      <td>1334</td>\n",
       "      <td>1334</td>\n",
       "      <td>1334</td>\n",
       "      <td>1334</td>\n",
       "      <td>1334</td>\n",
       "      <td>1334</td>\n",
       "      <td>1334</td>\n",
       "      <td>1334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue-collar</th>\n",
       "      <td>1944</td>\n",
       "      <td>1944</td>\n",
       "      <td>1944</td>\n",
       "      <td>1944</td>\n",
       "      <td>1944</td>\n",
       "      <td>1944</td>\n",
       "      <td>1944</td>\n",
       "      <td>1944</td>\n",
       "      <td>1944</td>\n",
       "      <td>1944</td>\n",
       "      <td>1944</td>\n",
       "      <td>1944</td>\n",
       "      <td>1944</td>\n",
       "      <td>1944</td>\n",
       "      <td>1944</td>\n",
       "      <td>1944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entrepreneur</th>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housemaid</th>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>management</th>\n",
       "      <td>2566</td>\n",
       "      <td>2566</td>\n",
       "      <td>2566</td>\n",
       "      <td>2566</td>\n",
       "      <td>2566</td>\n",
       "      <td>2566</td>\n",
       "      <td>2566</td>\n",
       "      <td>2566</td>\n",
       "      <td>2566</td>\n",
       "      <td>2566</td>\n",
       "      <td>2566</td>\n",
       "      <td>2566</td>\n",
       "      <td>2566</td>\n",
       "      <td>2566</td>\n",
       "      <td>2566</td>\n",
       "      <td>2566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retired</th>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self-employed</th>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>services</th>\n",
       "      <td>923</td>\n",
       "      <td>923</td>\n",
       "      <td>923</td>\n",
       "      <td>923</td>\n",
       "      <td>923</td>\n",
       "      <td>923</td>\n",
       "      <td>923</td>\n",
       "      <td>923</td>\n",
       "      <td>923</td>\n",
       "      <td>923</td>\n",
       "      <td>923</td>\n",
       "      <td>923</td>\n",
       "      <td>923</td>\n",
       "      <td>923</td>\n",
       "      <td>923</td>\n",
       "      <td>923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student</th>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technician</th>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unemployed</th>\n",
       "      <td>357</td>\n",
       "      <td>357</td>\n",
       "      <td>357</td>\n",
       "      <td>357</td>\n",
       "      <td>357</td>\n",
       "      <td>357</td>\n",
       "      <td>357</td>\n",
       "      <td>357</td>\n",
       "      <td>357</td>\n",
       "      <td>357</td>\n",
       "      <td>357</td>\n",
       "      <td>357</td>\n",
       "      <td>357</td>\n",
       "      <td>357</td>\n",
       "      <td>357</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unknown</th>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age  marital  education  default  balance  housing  loan  \\\n",
       "job                                                                        \n",
       "admin.         1334     1334       1334     1334     1334     1334  1334   \n",
       "blue-collar    1944     1944       1944     1944     1944     1944  1944   \n",
       "entrepreneur    328      328        328      328      328      328   328   \n",
       "housemaid       274      274        274      274      274      274   274   \n",
       "management     2566     2566       2566     2566     2566     2566  2566   \n",
       "retired         778      778        778      778      778      778   778   \n",
       "self-employed   405      405        405      405      405      405   405   \n",
       "services        923      923        923      923      923      923   923   \n",
       "student         360      360        360      360      360      360   360   \n",
       "technician     1823     1823       1823     1823     1823     1823  1823   \n",
       "unemployed      357      357        357      357      357      357   357   \n",
       "unknown          70       70         70       70       70       70    70   \n",
       "\n",
       "               contact   day  month  duration  campaign  pdays  previous  \\\n",
       "job                                                                        \n",
       "admin.            1334  1334   1334      1334      1334   1334      1334   \n",
       "blue-collar       1944  1944   1944      1944      1944   1944      1944   \n",
       "entrepreneur       328   328    328       328       328    328       328   \n",
       "housemaid          274   274    274       274       274    274       274   \n",
       "management        2566  2566   2566      2566      2566   2566      2566   \n",
       "retired            778   778    778       778       778    778       778   \n",
       "self-employed      405   405    405       405       405    405       405   \n",
       "services           923   923    923       923       923    923       923   \n",
       "student            360   360    360       360       360    360       360   \n",
       "technician        1823  1823   1823      1823      1823   1823      1823   \n",
       "unemployed         357   357    357       357       357    357       357   \n",
       "unknown             70    70     70        70        70     70        70   \n",
       "\n",
       "               poutcome  deposit  \n",
       "job                               \n",
       "admin.             1334     1334  \n",
       "blue-collar        1944     1944  \n",
       "entrepreneur        328      328  \n",
       "housemaid           274      274  \n",
       "management         2566     2566  \n",
       "retired             778      778  \n",
       "self-employed       405      405  \n",
       "services            923      923  \n",
       "student             360      360  \n",
       "technician         1823     1823  \n",
       "unemployed          357      357  \n",
       "unknown              70       70  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('job').agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job\n",
       "admin.            631\n",
       "blue-collar       708\n",
       "entrepreneur      123\n",
       "housemaid         109\n",
       "management       1301\n",
       "retired           516\n",
       "self-employed     187\n",
       "services          369\n",
       "student           269\n",
       "technician        840\n",
       "unemployed        202\n",
       "unknown            34\n",
       "Name: deposit, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data.groupby(['deposit', 'job'])['deposit'].agg('count')['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To see if people of any profession are more inclined towards our compaign\n",
    "import matplotlib.pyplot as plt\n",
    "pie_var1 = data.groupby(['deposit', 'job'])['deposit'].agg('count')['yes']\n",
    "fig1, ax2 = plt.subplots()\n",
    "plt.figure(1, figsize=(40,20))\n",
    "ax2.pie(pie_var1,labels=list(pie_var1.index),autopct='%1.1f%%')\n",
    "ax2.axis('equal')\n",
    "plt.title('Job with respect to Yes')\n",
    "plt.show()\n",
    "#Observation: There is no major inclination of people of any profession since these distribution is more or less the same as compared to the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "education_yes = data.groupby(['deposit','education'])['deposit'].agg('count')['yes'].values\n",
    "education_no = data.groupby(['deposit','education'])['deposit'].agg('count')['no'].values\n",
    "index = data.groupby(['deposit','education'])['deposit'].agg('count')['yes'].index\n",
    "df1 = df = pd.DataFrame({'education_yes': education_yes,\n",
    "                   'education_no': education_no}, index=index)\n",
    "ax = df.plot.bar(rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'no', 1: 'yes'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data1 = pd.get_dummies(data['deposit'])\n",
    "# converting the categorical deposit feature to binary using sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "labels_coulumn=encoder.fit_transform(data['deposit'])\n",
    "deposit_mappings = {index: label for index, label in \n",
    "                  enumerate(encoder.classes_)}\n",
    "deposit_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'admin.',\n",
       " 1: 'blue-collar',\n",
       " 2: 'entrepreneur',\n",
       " 3: 'housemaid',\n",
       " 4: 'management',\n",
       " 5: 'retired',\n",
       " 6: 'self-employed',\n",
       " 7: 'services',\n",
       " 8: 'student',\n",
       " 9: 'technician',\n",
       " 10: 'unemployed',\n",
       " 11: 'unknown'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_coulumn=encoder.fit_transform(data['job'])\n",
    "job_mappings = {index: label for index, label in \n",
    "                  enumerate(encoder.classes_)}\n",
    "job_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'divorced', 1: 'married', 2: 'single'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marital_coulumn=encoder.fit_transform(data['marital'])\n",
    "marital_mappings = {index: label for index, label in \n",
    "                  enumerate(encoder.classes_)}\n",
    "marital_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'primary', 1: 'secondary', 2: 'tertiary', 3: 'unknown'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education_coulumn=encoder.fit_transform(data['education'])\n",
    "education_mappings = {index: label for index, label in \n",
    "                  enumerate(encoder.classes_)}\n",
    "education_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'no', 1: 'yes'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_coulumn=encoder.fit_transform(data['default'])\n",
    "default_mappings = {index: label for index, label in \n",
    "                  enumerate(encoder.classes_)}\n",
    "default_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'no', 1: 'yes'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_coulumn=encoder.fit_transform(data['housing'])\n",
    "housing_mappings = {index: label for index, label in \n",
    "                  enumerate(encoder.classes_)}\n",
    "housing_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'no', 1: 'yes'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_coulumn=encoder.fit_transform(data['loan'])\n",
    "loan_mappings = {index: label for index, label in \n",
    "                  enumerate(encoder.classes_)}\n",
    "loan_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'cellular', 1: 'telephone', 2: 'unknown'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contact_coulumn=encoder.fit_transform(data['contact'])\n",
    "contact_mappings = {index: label for index, label in \n",
    "                  enumerate(encoder.classes_)}\n",
    "contact_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'apr',\n",
       " 1: 'aug',\n",
       " 2: 'dec',\n",
       " 3: 'feb',\n",
       " 4: 'jan',\n",
       " 5: 'jul',\n",
       " 6: 'jun',\n",
       " 7: 'mar',\n",
       " 8: 'may',\n",
       " 9: 'nov',\n",
       " 10: 'oct',\n",
       " 11: 'sep'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_coulumn=encoder.fit_transform(data['month'])\n",
    "month_mappings = {index: label for index, label in \n",
    "                  enumerate(encoder.classes_)}\n",
    "month_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'failure', 1: 'other', 2: 'success', 3: 'unknown'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poutcome_coulumn=encoder.fit_transform(data['poutcome'])\n",
    "poutcome_mappings = {index: label for index, label in \n",
    "                  enumerate(encoder.classes_)}\n",
    "poutcome_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5289</th>\n",
       "      <td>57</td>\n",
       "      <td>retired</td>\n",
       "      <td>single</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>604</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>19</td>\n",
       "      <td>nov</td>\n",
       "      <td>187</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5290</th>\n",
       "      <td>45</td>\n",
       "      <td>admin.</td>\n",
       "      <td>divorced</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5291</th>\n",
       "      <td>48</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>238</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>2</td>\n",
       "      <td>jun</td>\n",
       "      <td>118</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>success</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5292</th>\n",
       "      <td>34</td>\n",
       "      <td>admin.</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>673</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>29</td>\n",
       "      <td>jan</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>2</td>\n",
       "      <td>failure</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age          job   marital  education default  balance housing loan  \\\n",
       "5289   57      retired    single    primary      no      604      no   no   \n",
       "5290   45       admin.  divorced  secondary      no        0     yes   no   \n",
       "5291   48  blue-collar   married  secondary      no      238     yes  yes   \n",
       "5292   34       admin.    single  secondary      no      673     yes   no   \n",
       "\n",
       "       contact  day month  duration  campaign  pdays  previous poutcome  \\\n",
       "5289  cellular   19   nov       187         1     -1         0  unknown   \n",
       "5290  cellular   17   nov       102         1     -1         0  unknown   \n",
       "5291  cellular    2   jun       118         2     81         1  success   \n",
       "5292  cellular   29   jan        89         1    260         2  failure   \n",
       "\n",
       "      deposit  \n",
       "5289        0  \n",
       "5290        0  \n",
       "5291        0  \n",
       "5292        0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# writing down this transformed column in our DataFrame\n",
    "data['deposit']=labels_coulumn\n",
    "data[5289:5293]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['job']=job_coulumn\n",
    "data['marital']=marital_coulumn\n",
    "data['education']=education_coulumn\n",
    "data['default']=default_coulumn\n",
    "data['housing']=housing_coulumn\n",
    "data['loan']=loan_coulumn\n",
    "data['contact']=contact_coulumn\n",
    "data['month']=month_coulumn\n",
    "data['poutcome']=poutcome_coulumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': Int64Index([ 5289,  5290,  5291,  5292,  5293,  5294,  5295,  5296,  5297,\n",
       "              5298,\n",
       "             ...\n",
       "             11152, 11153, 11154, 11155, 11156, 11157, 11158, 11159, 11160,\n",
       "             11161],\n",
       "            dtype='int64', length=5873),\n",
       " 'yes': Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
       "             ...\n",
       "             5279, 5280, 5281, 5282, 5283, 5284, 5285, 5286, 5287, 5288],\n",
       "            dtype='int64', length=5289)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('deposit').groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2343</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1467</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1270</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1389</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2476</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>673</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  default  balance  housing  loan  contact  \\\n",
       "0   59    0        1          1        0     2343        1     0        2   \n",
       "1   56    0        1          1        0       45        0     0        2   \n",
       "2   41    9        1          1        0     1270        1     0        2   \n",
       "3   55    7        1          1        0     2476        1     0        2   \n",
       "4   54    0        1          2        0      184        0     0        2   \n",
       "\n",
       "   day  month  duration  campaign  pdays  previous  poutcome  deposit  \n",
       "0    5      8      1042         1     -1         0         3        1  \n",
       "1    5      8      1467         1     -1         0         3        1  \n",
       "2    5      8      1389         1     -1         0         3        1  \n",
       "3    5      8       579         1     -1         0         3        1  \n",
       "4    5      8       673         2     -1         0         3        1  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data['previous'].value_counts()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2343</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  default  balance  housing  loan  contact  \\\n",
       "0   59    0        1          1        0     2343        1     0        2   \n",
       "\n",
       "   day  month  duration  campaign  pdays  previous  poutcome  \n",
       "0    5      8      1042         1     -1         0         3  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before we go ahead and build any machine learning models from this data, let's split the data with 80:20.\n",
    "y = data['deposit'].values\n",
    "X = data.drop(['deposit'], axis=1)\n",
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:  (11162, 16)\n",
      "Shape of y:  (11162,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X: ',X.shape)\n",
    "print('Shape of y: ',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into train and test(80:20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "# X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=0.33, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (8929, 16)\n",
      "Shape of X_test:  (2233, 16)\n",
      "Shape of y_train (8929,)\n",
      "Shape of y_test (2233,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X_train: ',X_train.shape)\n",
    "print('Shape of X_test: ', X_test.shape)\n",
    "print('Shape of y_train', y_train.shape)\n",
    "print('Shape of y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning models for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 0.01, 'penalty': 'l2'}\n",
      "accuracy : 0.7621213072276147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# let's create models through trying out multiple parameters and finding out the best model with the best parameters. \n",
    "# For this we will be using gridSearchCV technique.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "parameters = {\"C\":np.logspace(-7,3,7),\"penalty\":['l1','l2']}\n",
    "log_reg=LogisticRegression()\n",
    "clf=GridSearchCV(log_reg, parameters, cv=10)\n",
    "clf.fit(X_train,y_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",clf.best_params_)\n",
    "print(\"accuracy :\",clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.7769816390506046\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79      1164\n",
      "           1       0.78      0.74      0.76      1069\n",
      "\n",
      "    accuracy                           0.78      2233\n",
      "   macro avg       0.78      0.78      0.78      2233\n",
      "weighted avg       0.78      0.78      0.78      2233\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "clf=log_reg=LogisticRegression(C=0.01, penalty= 'l2', solver='lbfgs',max_iter= 500)\n",
    "clf.fit(X_train,y_train)\n",
    "print(\"score\",clf.score(X_test,y_test))\n",
    "print(metrics.classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.16807194])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
       "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
       "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 2.65, NNZs: 16, Bias: -0.069720, T: 8929, Avg. loss: 291.804860\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3.89, NNZs: 16, Bias: -0.107593, T: 17858, Avg. loss: 313.862183\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.50, NNZs: 16, Bias: -0.138265, T: 26787, Avg. loss: 346.909457\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.84, NNZs: 16, Bias: -0.157204, T: 35716, Avg. loss: 301.348564\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5.30, NNZs: 16, Bias: -0.181096, T: 44645, Avg. loss: 310.133667\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5.44, NNZs: 16, Bias: -0.200467, T: 53574, Avg. loss: 269.064923\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 5.58, NNZs: 16, Bias: -0.221554, T: 62503, Avg. loss: 349.461119\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 5.65, NNZs: 16, Bias: -0.237215, T: 71432, Avg. loss: 278.963154\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 5.75, NNZs: 16, Bias: -0.253260, T: 80361, Avg. loss: 305.646205\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 6.37, NNZs: 16, Bias: -0.272023, T: 89290, Avg. loss: 324.805445\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 5.99, NNZs: 16, Bias: -0.283998, T: 98219, Avg. loss: 312.071050\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 11 epochs took 0.02 seconds\n",
      "score 0.580832960143305\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X=X_train, y=y_train) # fitting our model\n",
    "print(\"score\",clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's try with the scaled features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorizations\n",
      "(8929, 1) (8929,)\n",
      "(2233, 1) (2233,)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# X_train['age'].head()\n",
    "from sklearn.preprocessing import Normalizer\n",
    "normalizer = Normalizer()\n",
    "normalizer.fit(X_train['age'].values.reshape(-1,1))\n",
    "\n",
    "X_train_age_norm = normalizer.transform(X_train['age'].values.reshape(-1,1))\n",
    "X_test_age_norm = normalizer.transform(X_test['age'].values.reshape(-1,1))\n",
    "\n",
    "print(\"After vectorizations\")\n",
    "print(X_train_age_norm.shape, y_train.shape)\n",
    "print(X_test_age_norm.shape, y_test.shape)\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorizations\n",
      "(8929, 12) (8929,)\n",
      "(2233, 12) (2233,)\n",
      "['x0_0' 'x0_1' 'x0_2' 'x0_3' 'x0_4' 'x0_5' 'x0_6' 'x0_7' 'x0_8' 'x0_9'\n",
      " 'x0_10' 'x0_11']\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "vectorizer = OneHotEncoder()\n",
    "vectorizer.fit(X_train['job'].values.reshape(-1, 1)) # fit has to happen only on train data\n",
    "\n",
    "X_train_job_ohe = vectorizer.transform(X_train['job'].values.reshape(-1,1))\n",
    "# X_cv_state_ohe = vectorizer.transform(X_cv['school_state'].values)\n",
    "X_test_job_ohe = vectorizer.transform(X_test['job'].values.reshape(-1,1))\n",
    "\n",
    "print(\"After vectorizations\")\n",
    "print(X_train_job_ohe.shape, y_train.shape)\n",
    "# print(X_cv_state_ohe.shape, y_cv.shape)\n",
    "print(X_test_job_ohe.shape, y_test.shape)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorizations\n",
      "(8929, 3) (8929,)\n",
      "(2233, 3) (2233,)\n",
      "['x0_0' 'x0_1' 'x0_2']\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "vectorizer = OneHotEncoder()\n",
    "vectorizer.fit(X_train['marital'].values.reshape(-1, 1)) # fit has to happen only on train data\n",
    "\n",
    "X_train_marital_ohe = vectorizer.transform(X_train['marital'].values.reshape(-1,1))\n",
    "# X_cv_state_ohe = vectorizer.transform(X_cv['school_state'].values)\n",
    "X_test_marital_ohe = vectorizer.transform(X_test['marital'].values.reshape(-1,1))\n",
    "\n",
    "print(\"After vectorizations\")\n",
    "print(X_train_marital_ohe.shape, y_train.shape)\n",
    "# print(X_cv_state_ohe.shape, y_cv.shape)\n",
    "print(X_test_marital_ohe.shape, y_test.shape)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorizations\n",
      "(8929, 4) (8929,)\n",
      "(2233, 4) (2233,)\n",
      "['x0_0' 'x0_1' 'x0_2' 'x0_3']\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "vectorizer = OneHotEncoder()\n",
    "vectorizer.fit(X_train['education'].values.reshape(-1, 1)) # fit has to happen only on train data\n",
    "\n",
    "X_train_education_ohe = vectorizer.transform(X_train['education'].values.reshape(-1,1))\n",
    "X_test_education_ohe = vectorizer.transform(X_test['education'].values.reshape(-1,1))\n",
    "\n",
    "print(\"After vectorizations\")\n",
    "print(X_train_education_ohe.shape, y_train.shape)\n",
    "print(X_test_education_ohe.shape, y_test.shape)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorizations\n",
      "(8929, 1) (8929,)\n",
      "(2233, 1) (2233,)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "normalizer = Normalizer()\n",
    "normalizer.fit(X_train['balance'].values.reshape(-1,1))\n",
    "\n",
    "X_train_balance_norm = normalizer.transform(X_train['balance'].values.reshape(-1,1))\n",
    "X_test_balance_norm = normalizer.transform(X_test['balance'].values.reshape(-1,1))\n",
    "\n",
    "print(\"After vectorizations\")\n",
    "print(X_train_balance_norm.shape, y_train.shape)\n",
    "print(X_test_balance_norm.shape, y_test.shape)\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorizations\n",
      "(8929, 3) (8929,)\n",
      "(2233, 3) (2233,)\n",
      "['x0_0' 'x0_1' 'x0_2']\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "vectorizer = OneHotEncoder()\n",
    "vectorizer.fit(X_train['contact'].values.reshape(-1, 1)) # fit has to happen only on train data\n",
    "\n",
    "X_train_contact_ohe = vectorizer.transform(X_train['contact'].values.reshape(-1,1))\n",
    "X_test_contact_ohe = vectorizer.transform(X_test['contact'].values.reshape(-1,1))\n",
    "\n",
    "print(\"After vectorizations\")\n",
    "print(X_train_contact_ohe.shape, y_train.shape)\n",
    "print(X_test_contact_ohe.shape, y_test.shape)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorizations\n",
      "(8929, 31) (8929,)\n",
      "(2233, 31) (2233,)\n",
      "['x0_1' 'x0_2' 'x0_3' 'x0_4' 'x0_5' 'x0_6' 'x0_7' 'x0_8' 'x0_9' 'x0_10'\n",
      " 'x0_11' 'x0_12' 'x0_13' 'x0_14' 'x0_15' 'x0_16' 'x0_17' 'x0_18' 'x0_19'\n",
      " 'x0_20' 'x0_21' 'x0_22' 'x0_23' 'x0_24' 'x0_25' 'x0_26' 'x0_27' 'x0_28'\n",
      " 'x0_29' 'x0_30' 'x0_31']\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "vectorizer = OneHotEncoder()\n",
    "vectorizer.fit(X_train['day'].values.reshape(-1, 1)) # fit has to happen only on train data\n",
    "\n",
    "X_train_day_ohe = vectorizer.transform(X_train['day'].values.reshape(-1,1))\n",
    "X_test_day_ohe = vectorizer.transform(X_test['day'].values.reshape(-1,1))\n",
    "\n",
    "print(\"After vectorizations\")\n",
    "print(X_train_day_ohe.shape, y_train.shape)\n",
    "print(X_test_day_ohe.shape, y_test.shape)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorizations\n",
      "(8929, 12) (8929,)\n",
      "(2233, 12) (2233,)\n",
      "['x0_0' 'x0_1' 'x0_2' 'x0_3' 'x0_4' 'x0_5' 'x0_6' 'x0_7' 'x0_8' 'x0_9'\n",
      " 'x0_10' 'x0_11']\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "vectorizer = OneHotEncoder()\n",
    "vectorizer.fit(X_train['month'].values.reshape(-1, 1)) # fit has to happen only on train data\n",
    "\n",
    "X_train_month_ohe = vectorizer.transform(X_train['month'].values.reshape(-1,1))\n",
    "X_test_month_ohe = vectorizer.transform(X_test['month'].values.reshape(-1,1))\n",
    "\n",
    "print(\"After vectorizations\")\n",
    "print(X_train_month_ohe.shape, y_train.shape)\n",
    "print(X_test_month_ohe.shape, y_test.shape)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorizations\n",
      "(8929, 1) (8929,)\n",
      "(2233, 1) (2233,)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "normalizer = Normalizer()\n",
    "normalizer.fit(X_train['duration'].values.reshape(-1,1))\n",
    "\n",
    "X_train_duration_norm = normalizer.transform(X_train['duration'].values.reshape(-1,1))\n",
    "X_test_duration_norm = normalizer.transform(X_test['duration'].values.reshape(-1,1))\n",
    "\n",
    "print(\"After vectorizations\")\n",
    "print(X_train_duration_norm.shape, y_train.shape)\n",
    "print(X_test_duration_norm.shape, y_test.shape)\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorizations\n",
      "(8929, 1) (8929,)\n",
      "(2233, 1) (2233,)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "normalizer = Normalizer()\n",
    "normalizer.fit(X_train['campaign'].values.reshape(-1,1))\n",
    "\n",
    "X_train_campaign_norm = normalizer.transform(X_train['campaign'].values.reshape(-1,1))\n",
    "X_test_campaign_norm = normalizer.transform(X_test['campaign'].values.reshape(-1,1))\n",
    "\n",
    "print(\"After vectorizations\")\n",
    "print(X_train_campaign_norm.shape, y_train.shape)\n",
    "print(X_test_campaign_norm.shape, y_test.shape)\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorizations\n",
      "(8929, 1) (8929,)\n",
      "(2233, 1) (2233,)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "normalizer = Normalizer()\n",
    "normalizer.fit(X_train['pdays'].values.reshape(-1,1))\n",
    "\n",
    "X_train_pdays_norm = normalizer.transform(X_train['pdays'].values.reshape(-1,1))\n",
    "X_test_pdays_norm = normalizer.transform(X_test['pdays'].values.reshape(-1,1))\n",
    "\n",
    "print(\"After vectorizations\")\n",
    "print(X_train_pdays_norm.shape, y_train.shape)\n",
    "print(X_test_pdays_norm.shape, y_test.shape)\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorizations\n",
      "(8929, 1) (8929,)\n",
      "(2233, 1) (2233,)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "normalizer = Normalizer()\n",
    "normalizer.fit(X_train['previous'].values.reshape(-1,1))\n",
    "\n",
    "X_train_previous_norm = normalizer.transform(X_train['previous'].values.reshape(-1,1))\n",
    "X_test_previous_norm = normalizer.transform(X_test['previous'].values.reshape(-1,1))\n",
    "\n",
    "print(\"After vectorizations\")\n",
    "print(X_train_previous_norm.shape, y_train.shape)\n",
    "print(X_test_previous_norm.shape, y_test.shape)\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorizations\n",
      "(8929, 4) (8929,)\n",
      "(2233, 4) (2233,)\n",
      "['x0_0' 'x0_1' 'x0_2' 'x0_3']\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "vectorizer = OneHotEncoder()\n",
    "vectorizer.fit(X_train['poutcome'].values.reshape(-1, 1)) # fit has to happen only on train data\n",
    "\n",
    "X_train_poutcome_ohe = vectorizer.transform(X_train['poutcome'].values.reshape(-1,1))\n",
    "X_test_poutcome_ohe = vectorizer.transform(X_test['poutcome'].values.reshape(-1,1))\n",
    "\n",
    "print(\"After vectorizations\")\n",
    "print(X_train_poutcome_ohe.shape, y_train.shape)\n",
    "print(X_test_poutcome_ohe.shape, y_test.shape)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train_default:  (8929, 1)\n",
      "shape of X_test_default:  (2233, 1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "shape of X_train_housing:  (8929, 1)\n",
      "shape of X_test_housing:  (2233, 1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "shape of X_train_loan:  (8929, 1)\n",
      "shape of X_test_loan:  (2233, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_default= X_train['default'].values.reshape(-1,1)\n",
    "X_test_default= X_test['default'].values.reshape(-1,1)\n",
    "print('shape of X_train_default: ',X_train_default.shape)\n",
    "print('shape of X_test_default: ',X_test_default.shape)\n",
    "print(\"-\"*100)\n",
    "X_train_housing= X_train['housing'].values.reshape(-1,1)\n",
    "X_test_housing= X_test['housing'].values.reshape(-1,1)\n",
    "print('shape of X_train_housing: ',X_train_housing.shape)\n",
    "print('shape of X_test_housing: ',X_test_housing.shape)\n",
    "print(\"-\"*100)\n",
    "X_train_loan= X_train['loan'].values.reshape(-1,1)\n",
    "X_test_loan= X_test['default'].values.reshape(-1,1)\n",
    "print('shape of X_train_loan: ',X_train_loan.shape)\n",
    "print('shape of X_test_loan: ',X_test_loan.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6902    0\n",
       "9241    0\n",
       "3154    0\n",
       "2082    0\n",
       "9129    0\n",
       "Name: default, dtype: int32"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_default.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_default' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b482685ec975>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# X_train_age_norm.head()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train_default\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_default' is not defined"
     ]
    }
   ],
   "source": [
    "# X_train_age_norm.head()\n",
    "X_train_default.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating all the Scaled and preprocessed features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Data matrix\n",
      "(8929, 78) (8929,)\n",
      "(2233, 78) (2233,)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "X_tr = hstack((X_train_age_norm, X_train_job_ohe, X_train_marital_ohe, X_train_education_ohe, X_train_default, X_train_balance_norm, X_train_housing, X_train_loan, X_train_contact_ohe, X_train_day_ohe, X_train_month_ohe, X_train_duration_norm, X_train_campaign_norm, X_train_pdays_norm, X_train_previous_norm,X_train_poutcome_ohe)).tocsr()\n",
    "X_te = hstack((X_test_age_norm, X_test_job_ohe, X_test_marital_ohe, X_test_education_ohe, X_test_default, X_test_balance_norm, X_test_housing, X_test_loan, X_test_contact_ohe, X_test_day_ohe, X_test_month_ohe, X_test_duration_norm, X_test_campaign_norm, X_test_pdays_norm, X_test_previous_norm,X_test_poutcome_ohe)).tocsr()\n",
    "\n",
    "print(\"Final Data matrix\")\n",
    "print(X_tr.shape, y_train.shape)\n",
    "print(X_te.shape, y_test.shape)\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Modelling with the Scaled Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 21.544346900318867, 'penalty': 'l2'}\n",
      "accuracy : 0.7029918800435877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# let's create models through trying out multiple parameters and finding out the best model with the best parameters. \n",
    "# For this we will be using gridSearchCV technique.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "parameters = {\"C\":np.logspace(-7,3,7),\"penalty\":['l1','l2']}\n",
    "log_reg=LogisticRegression()\n",
    "clf=GridSearchCV(log_reg, parameters, cv=10)\n",
    "clf.fit(X_tr,y_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",clf.best_params_)\n",
    "print(\"accuracy :\",clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Using SVM for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.7021943573667712\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.82      0.74      1164\n",
      "           1       0.75      0.57      0.65      1069\n",
      "\n",
      "    accuracy                           0.70      2233\n",
      "   macro avg       0.71      0.70      0.69      2233\n",
      "weighted avg       0.71      0.70      0.70      2233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "model=linear_model.SGDClassifier(loss='hinge')\n",
    "model.fit(X_tr,y_train)\n",
    "print(\"score\",model.score(X_te,y_test))\n",
    "print(metrics.classification_report(y_test, model.predict(X_te)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying with Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.605, test=0.607), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.606, test=0.605), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.607, test=0.590), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.603, test=0.624), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.603, test=0.624), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.607, test=0.596), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.607, test=0.596), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.607, test=0.591), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.605, test=0.609), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.605, test=0.613), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.605, test=0.607), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.606, test=0.605), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.607, test=0.590), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.603, test=0.624), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.603, test=0.624), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.607, test=0.596), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.607, test=0.596), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.607, test=0.591), total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.605, test=0.609), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.605, test=0.613), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.605, test=0.607), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.606, test=0.605), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.607, test=0.590), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.603, test=0.624), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.603, test=0.624), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.607, test=0.596), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.607, test=0.596), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.607, test=0.591), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.605, test=0.609), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.605, test=0.613), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.605, test=0.607), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.606, test=0.605), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.607, test=0.590), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.603, test=0.624), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.603, test=0.624), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.607, test=0.596), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.607, test=0.596), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.607, test=0.591), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.605, test=0.609), total=   0.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.605, test=0.613), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.693, test=0.679), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.682, test=0.709), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.694, test=0.684), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.692, test=0.703), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.692, test=0.686), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.696, test=0.670), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.694, test=0.683), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.695, test=0.677), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.694, test=0.680), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.692, test=0.696), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.693, test=0.679), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.682, test=0.708), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.694, test=0.684), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.692, test=0.703), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.692, test=0.686), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.695, test=0.671), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.694, test=0.683), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.694, test=0.677), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.694, test=0.680), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.692, test=0.697), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.692, test=0.679), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.681, test=0.709), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.691, test=0.682), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.691, test=0.703), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.691, test=0.686), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.693, test=0.667), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.693, test=0.684), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.692, test=0.680), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.691, test=0.679), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.691, test=0.696), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.692, test=0.679), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.681, test=0.709), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.691, test=0.682), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.691, test=0.703), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.691, test=0.686), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.693, test=0.666), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.693, test=0.684), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.692, test=0.680), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.691, test=0.680), total=   0.0s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.691, test=0.696), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.735, test=0.694), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.738, test=0.703), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.738, test=0.691), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.739, test=0.710), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.735, test=0.702), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.743, test=0.664), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.734, test=0.700), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.735, test=0.693), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.733, test=0.702), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.733, test=0.721), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.732, test=0.697), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.735, test=0.701), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.735, test=0.694), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.735, test=0.711), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.732, test=0.701), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.738, test=0.667), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.732, test=0.699), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.732, test=0.694), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.731, test=0.694), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.730, test=0.720), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.722, test=0.702), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.727, test=0.707), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.722, test=0.703), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.728, test=0.714), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.719, test=0.707), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.728, test=0.682), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.725, test=0.699), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.719, test=0.711), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.718, test=0.699), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.720, test=0.721), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.706, test=0.702), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.711, test=0.711), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.708, test=0.699), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.708, test=0.720), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.708, test=0.698), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.713, test=0.672), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.711, test=0.695), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.710, test=0.704), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.705, test=0.693), total=   0.0s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.711, test=0.714), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.894, test=0.641), total=   0.2s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.890, test=0.639), total=   0.2s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.888, test=0.653), total=   0.2s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.892, test=0.676), total=   0.2s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.892, test=0.630), total=   0.2s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.896, test=0.632), total=   0.2s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.894, test=0.660), total=   0.2s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.891, test=0.649), total=   0.2s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.894, test=0.638), total=   0.2s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.891, test=0.650), total=   0.2s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.852, test=0.654), total=   0.2s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.847, test=0.658), total=   0.2s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.844, test=0.667), total=   0.2s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.850, test=0.672), total=   0.2s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.850, test=0.639), total=   0.2s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.853, test=0.646), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.852, test=0.677), total=   0.2s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.853, test=0.652), total=   0.2s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.853, test=0.638), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.852, test=0.650), total=   0.2s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.753, test=0.690), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.750, test=0.710), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.753, test=0.713), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.755, test=0.691), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.752, test=0.699), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.758, test=0.694), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.756, test=0.699), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.752, test=0.710), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.751, test=0.707), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.751, test=0.704), total=   0.1s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.713, test=0.709), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.712, test=0.708), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.711, test=0.699), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.709, test=0.716), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.714, test=0.690), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.716, test=0.672), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.716, test=0.693), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.718, test=0.695), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.712, test=0.700), total=   0.0s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.715, test=0.709), total=   0.0s\n",
      "BEST DEPTH:  10 BEST MIN SAMPLE SPLITS:  100  BEST SCORE:  0.7044480237422102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:    7.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier(class_weight ='balanced')\n",
    "parameters = {'max_depth':[1, 5, 10, 50],'min_samples_split':[5, 10, 100, 500]}\n",
    "clf = GridSearchCV(dt_clf, parameters, cv= 10, scoring='accuracy', verbose=10,return_train_score=True)\n",
    "clf.fit(X_tr,y_train)\n",
    "train_score= clf.cv_results_['mean_train_score']\n",
    "train_score= clf.cv_results_['std_train_score']\n",
    "cv_score = clf.cv_results_['mean_test_score']\n",
    "cv_score = clf.cv_results_['std_test_score']\n",
    "bestDepth=clf.best_params_['max_depth']\n",
    "bestScore=clf.best_score_\n",
    "print(\"BEST DEPTH: \",clf.best_params_['max_depth'],\"BEST MIN SAMPLE SPLITS: \",clf.best_params_['min_samples_split'],\" BEST SCORE: \",clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.6918943125839677\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.79      0.73      1164\n",
      "           1       0.72      0.59      0.65      1069\n",
      "\n",
      "    accuracy                           0.69      2233\n",
      "   macro avg       0.70      0.69      0.69      2233\n",
      "weighted avg       0.70      0.69      0.69      2233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"score\",clf.score(X_te,y_test))\n",
    "print(metrics.classification_report(y_test, clf.predict(X_te)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST DEPTH:  50 BEST min_samples_split:  10  BEST SCORE:  0.8464544865646608\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf=RandomForestClassifier(random_state=51)\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "clf_rf = GridSearchCV(rf_clf, parameters, cv= 10, scoring='accuracy', verbose=10,return_train_score=True)\n",
    "clf_rf.fit(X_train,y_train)\n",
    "train_score= clf_rf.cv_results_['mean_train_score']\n",
    "train_score= clf_rf.cv_results_['std_train_score']\n",
    "cv_score = clf_rf.cv_results_['mean_test_score']\n",
    "cv_score = clf_rf.cv_results_['std_test_score']\n",
    "bestDepth=clf_rf.best_params_['max_depth']\n",
    "bestScore=clf_rf.best_score_\n",
    "print(\"BEST DEPTH: \",clf_rf.best_params_['max_depth'],\"BEST min_samples_split: \",clf_rf.best_params_['min_samples_split'],\" BEST SCORE: \",clf_rf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.8329601433049709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83      1164\n",
      "           1       0.79      0.88      0.83      1069\n",
      "\n",
      "    accuracy                           0.83      2233\n",
      "   macro avg       0.84      0.83      0.83      2233\n",
      "weighted avg       0.84      0.83      0.83      2233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"score\",clf_rf.score(X_test,y_test))\n",
    "print(metrics.classification_report(y_test, clf_rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.620, test=0.610), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.620, test=0.611), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.622, test=0.589), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.619, test=0.626), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.618, test=0.629), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.620, test=0.619), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    1.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.618, test=0.611), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    1.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.620, test=0.628), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    1.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.618, test=0.632), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    2.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.617, test=0.633), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.620, test=0.610), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.620, test=0.611), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.622, test=0.589), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.619, test=0.626), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.618, test=0.629), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.620, test=0.619), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.618, test=0.611), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.620, test=0.628), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.618, test=0.632), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.617, test=0.633), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.620, test=0.610), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.620, test=0.611), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.622, test=0.589), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.619, test=0.626), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.618, test=0.629), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.620, test=0.619), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.618, test=0.611), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.620, test=0.628), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.618, test=0.632), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.617, test=0.633), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.620, test=0.610), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.620, test=0.611), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.622, test=0.589), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.619, test=0.626), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.618, test=0.629), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.620, test=0.619), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.618, test=0.611), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.620, test=0.628), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.618, test=0.632), total=   0.2s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.617, test=0.633), total=   0.2s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.698, test=0.694), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.692, test=0.692), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.698, test=0.682), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.690, test=0.684), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.696, test=0.697), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.700, test=0.679), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.699, test=0.664), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.697, test=0.690), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.695, test=0.702), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.693, test=0.706), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.698, test=0.693), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.695, test=0.697), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.693, test=0.684), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.692, test=0.691), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.693, test=0.697), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.699, test=0.679), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.700, test=0.665), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.695, test=0.689), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.696, test=0.700), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.696, test=0.705), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.690, test=0.684), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.689, test=0.689), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.691, test=0.686), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.688, test=0.691), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.686, test=0.690), total=   0.2s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.690, test=0.669), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.690, test=0.657), total=   0.2s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.692, test=0.682), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.689, test=0.693), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.695, test=0.706), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.688, test=0.688), total=   0.2s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.686, test=0.684), total=   0.2s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.687, test=0.682), total=   0.2s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.687, test=0.683), total=   0.2s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.685, test=0.682), total=   0.2s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.692, test=0.671), total=   0.2s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.692, test=0.660), total=   0.2s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.692, test=0.679), total=   0.2s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.684, test=0.686), total=   0.3s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.687, test=0.705), total=   0.2s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.749, test=0.718), total=   0.6s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.748, test=0.737), total=   0.7s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.748, test=0.727), total=   0.7s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.747, test=0.722), total=   0.6s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.747, test=0.718), total=   0.6s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.749, test=0.691), total=   0.7s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.747, test=0.712), total=   0.7s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.751, test=0.700), total=   0.7s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.746, test=0.725), total=   0.7s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.746, test=0.731), total=   0.7s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.744, test=0.717), total=   0.6s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.740, test=0.732), total=   0.6s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.742, test=0.727), total=   0.6s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.742, test=0.726), total=   0.6s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.742, test=0.725), total=   0.6s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.747, test=0.694), total=   0.6s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.741, test=0.705), total=   0.6s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.746, test=0.698), total=   0.6s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.744, test=0.726), total=   0.6s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.744, test=0.722), total=   0.6s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.728, test=0.712), total=   0.4s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.727, test=0.728), total=   0.5s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.727, test=0.727), total=   0.4s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.729, test=0.721), total=   0.5s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.729, test=0.717), total=   0.5s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.732, test=0.697), total=   0.5s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.729, test=0.701), total=   0.5s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.730, test=0.695), total=   0.5s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.729, test=0.714), total=   0.5s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.730, test=0.720), total=   0.5s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.710, test=0.705), total=   0.3s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.710, test=0.721), total=   0.3s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.706, test=0.711), total=   0.3s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.709, test=0.718), total=   0.3s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.710, test=0.705), total=   0.3s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.713, test=0.682), total=   0.3s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.713, test=0.684), total=   0.3s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.713, test=0.691), total=   0.3s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.709, test=0.705), total=   0.3s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.711, test=0.719), total=   0.3s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.900, test=0.712), total=   4.1s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.900, test=0.723), total=   3.2s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.897, test=0.712), total=   3.9s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.895, test=0.717), total=   3.2s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.898, test=0.713), total=   3.2s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.898, test=0.694), total=   3.5s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.900, test=0.704), total=   3.3s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.901, test=0.709), total=   3.2s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.899, test=0.717), total=   3.2s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.899, test=0.709), total=   3.1s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.850, test=0.719), total=   2.6s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.850, test=0.739), total=   2.6s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.851, test=0.726), total=   2.5s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.850, test=0.729), total=   2.6s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.851, test=0.714), total=   2.6s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.852, test=0.700), total=   2.6s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.853, test=0.710), total=   2.5s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.849, test=0.713), total=   2.6s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.851, test=0.716), total=   2.6s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.851, test=0.723), total=   2.6s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.758, test=0.723), total=   0.9s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.757, test=0.744), total=   0.9s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.757, test=0.738), total=   0.9s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.756, test=0.732), total=   0.9s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.758, test=0.731), total=   0.9s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.762, test=0.700), total=   0.9s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.759, test=0.714), total=   0.9s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.758, test=0.711), total=   0.9s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.756, test=0.741), total=   0.9s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.756, test=0.731), total=   0.9s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.718, test=0.709), total=   0.4s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.711, test=0.721), total=   0.4s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.713, test=0.710), total=   0.4s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.717, test=0.717), total=   0.4s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.715, test=0.712), total=   0.4s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.718, test=0.683), total=   0.4s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.719, test=0.688), total=   0.4s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.719, test=0.690), total=   0.4s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.712, test=0.710), total=   0.4s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.714, test=0.714), total=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST DEPTH:  50 BEST min_samples_split:  100  BEST SCORE:  0.7266216060138898\n"
     ]
    }
   ],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "clf_rf2 = GridSearchCV(rf_clf, parameters, cv= 10, scoring='accuracy', verbose=10,return_train_score=True)\n",
    "clf_rf2.fit(X_tr,y_train)\n",
    "train_score= clf_rf2.cv_results_['mean_train_score']\n",
    "train_score= clf_rf2.cv_results_['std_train_score']\n",
    "cv_score = clf_rf2.cv_results_['mean_test_score']\n",
    "cv_score = clf_rf2.cv_results_['std_test_score']\n",
    "bestDepth=clf_rf2.best_params_['max_depth']\n",
    "bestScore=clf_rf2.best_score_\n",
    "print(\"BEST DEPTH: \",clf_rf2.best_params_['max_depth'],\"BEST min_samples_split: \",clf_rf2.best_params_['min_samples_split'],\" BEST SCORE: \",clf_rf2.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:22:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.701, test=0.713), total=   1.8s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[11:22:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.695, test=0.702), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[11:22:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.702, test=0.704), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[11:22:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.696, test=0.714), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[11:22:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.701, test=0.704), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[11:22:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.705, test=0.670), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[11:22:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    6.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.696, test=0.679), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[11:22:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    7.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.703, test=0.677), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[11:22:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    8.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.700, test=0.695), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[11:22:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    8.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.696, test=0.695), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[11:22:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.701, test=0.713), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[11:22:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.695, test=0.702), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[11:22:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.702, test=0.704), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[11:22:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.696, test=0.714), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[11:22:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.701, test=0.704), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[11:22:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.705, test=0.670), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[11:22:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.696, test=0.679), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[11:22:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.703, test=0.677), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[11:22:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.700, test=0.695), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[11:22:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.696, test=0.695), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[11:22:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.701, test=0.713), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[11:22:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.695, test=0.702), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[11:22:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.702, test=0.704), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[11:22:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.696, test=0.714), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[11:22:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.701, test=0.704), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[11:22:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.705, test=0.670), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[11:22:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.696, test=0.679), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[11:22:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.703, test=0.677), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[11:22:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.700, test=0.695), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[11:22:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.696, test=0.695), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[11:22:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.701, test=0.713), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[11:22:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.695, test=0.702), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[11:22:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.702, test=0.704), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[11:22:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.696, test=0.714), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[11:22:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.701, test=0.704), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[11:22:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.705, test=0.670), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[11:22:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.696, test=0.679), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[11:22:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.703, test=0.677), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[11:22:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.700, test=0.695), total=   0.8s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[11:22:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.696, test=0.695), total=   0.8s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[11:22:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.756, test=0.735), total=   2.1s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[11:22:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.757, test=0.740), total=   2.2s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[11:22:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.749, test=0.751), total=   2.1s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[11:22:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:22:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.752, test=0.731), total=   2.2s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[11:23:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.751, test=0.738), total=   2.1s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[11:23:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.756, test=0.692), total=   2.2s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[11:23:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.752, test=0.723), total=   2.2s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[11:23:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.755, test=0.700), total=   2.3s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[11:23:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.750, test=0.730), total=   2.2s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[11:23:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.754, test=0.741), total=   2.2s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[11:23:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.756, test=0.735), total=   2.4s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[11:23:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.757, test=0.740), total=   2.5s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[11:23:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.749, test=0.751), total=   2.5s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[11:23:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.752, test=0.731), total=   2.4s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[11:23:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.751, test=0.738), total=   2.3s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[11:23:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.756, test=0.692), total=   2.2s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[11:23:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.752, test=0.723), total=   2.3s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[11:23:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.755, test=0.700), total=   2.2s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[11:23:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.750, test=0.730), total=   2.3s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[11:23:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.754, test=0.741), total=   2.2s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[11:23:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.756, test=0.735), total=   2.3s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[11:23:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.757, test=0.740), total=   2.2s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[11:23:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.749, test=0.751), total=   2.2s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[11:23:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.752, test=0.731), total=   2.3s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[11:23:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.751, test=0.738), total=   2.2s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[11:23:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.756, test=0.692), total=   2.3s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[11:23:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.752, test=0.723), total=   2.2s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[11:23:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.755, test=0.700), total=   2.3s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[11:23:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.750, test=0.730), total=   2.2s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[11:23:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:23:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.754, test=0.741), total=   2.3s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[11:24:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:24:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.756, test=0.735), total=   2.2s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[11:24:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:24:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.757, test=0.740), total=   2.3s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[11:24:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:24:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.749, test=0.751), total=   2.3s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[11:24:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:24:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.752, test=0.731), total=   2.3s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[11:24:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:24:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.751, test=0.738), total=   2.3s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[11:24:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:24:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.756, test=0.692), total=   2.3s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[11:24:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:24:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.752, test=0.723), total=   2.3s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[11:24:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:24:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.755, test=0.700), total=   2.2s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[11:24:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:24:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.750, test=0.730), total=   2.5s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[11:24:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:24:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.754, test=0.741), total=   2.5s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[11:24:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:24:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.817, test=0.733), total=   4.6s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[11:24:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:24:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.819, test=0.722), total=   4.5s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[11:24:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:24:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.822, test=0.741), total=   4.6s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[11:24:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:24:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.820, test=0.712), total=   4.5s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[11:24:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:24:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.821, test=0.720), total=   4.6s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[11:24:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:24:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.823, test=0.693), total=   4.6s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[11:24:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:24:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.821, test=0.726), total=   4.5s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[11:24:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:24:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.818, test=0.721), total=   4.5s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[11:25:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:25:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.820, test=0.751), total=   4.5s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[11:25:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:25:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.822, test=0.730), total=   4.5s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[11:25:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:25:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.817, test=0.733), total=   4.5s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[11:25:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:25:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.819, test=0.722), total=   4.5s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[11:25:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:25:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.822, test=0.741), total=   4.5s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[11:25:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:25:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.820, test=0.712), total=   5.0s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[11:25:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:25:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.821, test=0.720), total=   4.5s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[11:25:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:25:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.823, test=0.693), total=   4.5s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[11:25:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:25:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.821, test=0.726), total=   4.4s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[11:25:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:25:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.818, test=0.721), total=   4.5s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[11:25:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:25:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.820, test=0.751), total=   4.6s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[11:25:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:25:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.822, test=0.730), total=   4.5s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[11:26:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:26:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.817, test=0.733), total=   4.4s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[11:26:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:26:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.819, test=0.722), total=   4.5s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[11:26:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:26:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.822, test=0.741), total=   4.5s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[11:26:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:26:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.820, test=0.712), total=   5.7s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[11:26:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:26:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.821, test=0.720), total=   4.8s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[11:26:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:26:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.823, test=0.693), total=   4.6s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[11:26:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:26:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.821, test=0.726), total=   4.7s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[11:26:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:26:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.818, test=0.721), total=   4.7s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[11:26:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:26:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.820, test=0.751), total=   4.5s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[11:26:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:26:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.822, test=0.730), total=   4.5s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[11:26:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:26:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.817, test=0.733), total=   4.5s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[11:26:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:26:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.819, test=0.722), total=   4.4s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[11:26:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:26:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.822, test=0.741), total=   4.6s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[11:27:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:27:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.820, test=0.712), total=   4.4s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[11:27:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:27:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.821, test=0.720), total=   4.5s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[11:27:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:27:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.823, test=0.693), total=   4.5s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[11:27:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:27:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.821, test=0.726), total=   4.4s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[11:27:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:27:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.818, test=0.721), total=   4.5s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[11:27:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:27:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.820, test=0.751), total=   4.5s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[11:27:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:27:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.822, test=0.730), total=   4.5s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[11:27:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:27:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.940, test=0.691), total=  22.4s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[11:27:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:27:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.941, test=0.690), total=  21.9s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[11:28:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.939, test=0.702), total=  21.8s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[11:28:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.940, test=0.698), total=  22.3s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[11:29:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.940, test=0.675), total=  21.8s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[11:29:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.940, test=0.669), total=  21.6s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[11:29:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.941, test=0.694), total=  22.0s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[11:30:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.941, test=0.675), total=  21.7s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[11:30:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.940, test=0.719), total=  21.9s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[11:31:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=0.941, test=0.697), total=  24.1s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[11:31:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.940, test=0.691), total=  24.1s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[11:31:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.941, test=0.690), total=  24.4s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[11:32:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:32:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.939, test=0.702), total=  22.0s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[11:32:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:32:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.940, test=0.698), total=  22.0s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[11:33:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:33:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.940, test=0.675), total=  22.2s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[11:33:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:33:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.940, test=0.669), total=  21.8s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[11:33:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:33:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.941, test=0.694), total=  21.8s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[11:34:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:34:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.941, test=0.675), total=  22.2s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[11:34:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:34:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.940, test=0.719), total=  21.8s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[11:34:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:34:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=0.941, test=0.697), total=  21.7s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[11:35:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:35:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.940, test=0.691), total=  22.8s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[11:35:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:35:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.941, test=0.690), total=  22.5s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[11:36:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:36:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.939, test=0.702), total=  21.8s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[11:36:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:36:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.940, test=0.698), total=  22.2s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[11:36:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:36:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.940, test=0.675), total=  21.7s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[11:37:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:37:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.940, test=0.669), total=  21.7s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[11:37:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:37:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.941, test=0.694), total=  22.0s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[11:37:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:37:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.941, test=0.675), total=  21.6s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[11:38:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:38:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.940, test=0.719), total=  22.1s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[11:38:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:38:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=0.941, test=0.697), total=  21.8s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[11:39:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:39:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.940, test=0.691), total=  21.9s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[11:39:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:39:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.941, test=0.690), total=  22.3s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[11:39:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:39:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.939, test=0.702), total=  21.7s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[11:40:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:40:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.940, test=0.698), total=  22.3s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[11:40:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:40:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.940, test=0.675), total=  22.0s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[11:40:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:40:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.940, test=0.669), total=  21.5s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[11:41:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:41:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.941, test=0.694), total=  21.8s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[11:41:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:41:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.941, test=0.675), total=  22.4s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[11:42:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:42:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.940, test=0.719), total=  21.7s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[11:42:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:42:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=0.941, test=0.697), total=  21.9s\n",
      "[11:42:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:42:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed: 20.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST DEPTH:  5 BEST min_samples_split:  5  BEST SCORE:  0.7266216060138898\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "clf_xgb = GridSearchCV(xgb, parameters, cv= 10, scoring='accuracy', verbose=10,return_train_score=True)\n",
    "clf_xgb.fit(X_tr,y_train)\n",
    "train_score= clf_xgb.cv_results_['mean_train_score']\n",
    "train_score= clf_xgb.cv_results_['std_train_score']\n",
    "cv_score = clf_xgb.cv_results_['mean_test_score']\n",
    "cv_score = clf_xgb.cv_results_['std_test_score']\n",
    "bestDepth=clf_xgb.best_params_['max_depth']\n",
    "bestScore=clf_xgb.best_score_\n",
    "print(\"BEST DEPTH: \",clf_xgb.best_params_['max_depth'],\"BEST min_samples_split: \",clf_xgb.best_params_['min_samples_split'],\" BEST SCORE: \",clf_rf2.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.7245857590685177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.84      0.76      1164\n",
      "           1       0.78      0.60      0.67      1069\n",
      "\n",
      "    accuracy                           0.72      2233\n",
      "   macro avg       0.74      0.72      0.72      2233\n",
      "weighted avg       0.73      0.72      0.72      2233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"score\",clf_xgb.score(X_te,y_test))\n",
    "print(metrics.classification_report(y_test, clf_xgb.predict(X_te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[14:51:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.816, test=0.832), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[14:51:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.816, test=0.811), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[14:51:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.816, test=0.804), total=   1.0s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[14:51:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.818, test=0.803), total=   1.2s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[14:51:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.815, test=0.814), total=   1.1s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[14:51:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.818, test=0.814), total=   1.2s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[14:51:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    6.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.818, test=0.811), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[14:51:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    7.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.820, test=0.804), total=   1.0s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[14:51:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    8.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.818, test=0.825), total=   1.0s\n",
      "[CV] max_depth=1, min_samples_split=5 ................................\n",
      "[14:51:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    9.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, min_samples_split=5, score=(train=0.818, test=0.802), total=   1.0s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[14:51:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.816, test=0.832), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[14:51:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.816, test=0.811), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[14:51:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.816, test=0.804), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[14:51:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.818, test=0.803), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[14:51:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.815, test=0.814), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[14:51:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.818, test=0.814), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[14:51:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.818, test=0.811), total=   1.0s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[14:51:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.820, test=0.804), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[14:51:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.818, test=0.825), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=10 ...............................\n",
      "[14:51:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=10, score=(train=0.818, test=0.802), total=   1.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[14:51:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.816, test=0.832), total=   1.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[14:51:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.816, test=0.811), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[14:51:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.816, test=0.804), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[14:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.818, test=0.803), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[14:51:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.815, test=0.814), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[14:51:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.818, test=0.814), total=   1.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[14:51:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.818, test=0.811), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[14:51:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.820, test=0.804), total=   1.0s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[14:51:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.818, test=0.825), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=100 ..............................\n",
      "[14:51:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=100, score=(train=0.818, test=0.802), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[14:51:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.816, test=0.832), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[14:51:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.816, test=0.811), total=   1.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[14:51:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.816, test=0.804), total=   1.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[14:51:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.818, test=0.803), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[14:51:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.815, test=0.814), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[14:51:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.818, test=0.814), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[14:51:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.818, test=0.811), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[14:51:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.820, test=0.804), total=   0.9s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[14:51:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.818, test=0.825), total=   1.0s\n",
      "[CV] max_depth=1, min_samples_split=500 ..............................\n",
      "[14:51:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=1, min_samples_split=500, score=(train=0.818, test=0.802), total=   0.9s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[14:51:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.895, test=0.872), total=   3.3s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[14:51:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.891, test=0.860), total=   3.6s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[14:51:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.892, test=0.877), total=   3.7s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[14:51:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:51:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.897, test=0.850), total=   3.5s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[14:52:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:52:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.896, test=0.857), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[14:52:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:52:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.893, test=0.853), total=   3.3s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[14:52:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:52:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.896, test=0.857), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[14:52:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:52:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.894, test=0.841), total=   3.3s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[14:52:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:52:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.894, test=0.867), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=5 ................................\n",
      "[14:52:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:52:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=5, score=(train=0.898, test=0.840), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[14:52:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:52:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.895, test=0.872), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[14:52:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:52:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.891, test=0.860), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[14:52:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:52:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.892, test=0.877), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[14:52:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:52:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.897, test=0.850), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[14:52:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:52:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.896, test=0.857), total=   3.5s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[14:52:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:52:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.893, test=0.853), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[14:52:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:52:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.896, test=0.857), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[14:52:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:52:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.894, test=0.841), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[14:52:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:52:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.894, test=0.867), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=10 ...............................\n",
      "[14:52:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:52:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=10, score=(train=0.898, test=0.840), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[14:52:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:52:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.895, test=0.872), total=   3.7s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[14:53:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:53:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.891, test=0.860), total=   3.5s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[14:53:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:53:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.892, test=0.877), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[14:53:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:53:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.897, test=0.850), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[14:53:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:53:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.896, test=0.857), total=   3.5s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[14:53:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:53:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.893, test=0.853), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[14:53:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:53:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.896, test=0.857), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[14:53:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:53:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.894, test=0.841), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[14:53:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:53:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.894, test=0.867), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=100 ..............................\n",
      "[14:53:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:53:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=100, score=(train=0.898, test=0.840), total=   3.5s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[14:53:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:53:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.895, test=0.872), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[14:53:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:53:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.891, test=0.860), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[14:53:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:53:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.892, test=0.877), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[14:53:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:53:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.897, test=0.850), total=   4.2s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[14:53:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:53:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.896, test=0.857), total=   3.5s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[14:53:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:53:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.893, test=0.853), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[14:53:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:53:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.896, test=0.857), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[14:53:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:53:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.894, test=0.841), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[14:54:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:54:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.894, test=0.867), total=   3.4s\n",
      "[CV] max_depth=5, min_samples_split=500 ..............................\n",
      "[14:54:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:54:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=5, min_samples_split=500, score=(train=0.898, test=0.840), total=   4.4s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[14:54:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:54:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.988, test=0.877), total=   8.1s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[14:54:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:54:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.982, test=0.861), total=   7.7s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[14:54:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:54:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.987, test=0.876), total=   7.9s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[14:54:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:54:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.984, test=0.851), total=   8.1s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[14:54:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:54:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.985, test=0.859), total=   7.8s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[14:54:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:54:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.988, test=0.861), total=   7.9s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[14:54:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:54:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.988, test=0.865), total=   8.0s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[14:55:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:55:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.985, test=0.848), total=   8.2s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[14:55:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:55:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.985, test=0.868), total=   8.4s\n",
      "[CV] max_depth=10, min_samples_split=5 ...............................\n",
      "[14:55:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:55:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=5, score=(train=0.991, test=0.849), total=   8.0s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[14:55:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:55:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.988, test=0.877), total=   7.8s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[14:55:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:55:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.982, test=0.861), total=   7.6s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[14:55:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:55:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.987, test=0.876), total=   7.9s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[14:55:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:55:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.984, test=0.851), total=   7.8s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[14:56:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:56:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.985, test=0.859), total=   7.8s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[14:56:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:56:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.988, test=0.861), total=   8.0s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[14:56:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:56:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.988, test=0.865), total=   8.4s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[14:56:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:56:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.985, test=0.848), total=   7.9s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[14:56:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:56:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.985, test=0.868), total=   7.8s\n",
      "[CV] max_depth=10, min_samples_split=10 ..............................\n",
      "[14:56:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:56:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=10, score=(train=0.991, test=0.849), total=   7.9s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[14:56:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:56:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.988, test=0.877), total=   7.8s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[14:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.982, test=0.861), total=   7.6s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[14:57:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:57:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.987, test=0.876), total=   7.9s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[14:57:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:57:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.984, test=0.851), total=   8.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[14:57:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:57:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.985, test=0.859), total=   8.0s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[14:57:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:57:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.988, test=0.861), total=   7.8s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[14:57:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:57:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.988, test=0.865), total=   7.9s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[14:57:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:57:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.985, test=0.848), total=   7.8s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[14:57:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:57:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.985, test=0.868), total=   7.8s\n",
      "[CV] max_depth=10, min_samples_split=100 .............................\n",
      "[14:58:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:58:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=100, score=(train=0.991, test=0.849), total=   7.9s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[14:58:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:58:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.988, test=0.877), total=   7.8s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[14:58:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:58:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.982, test=0.861), total=   7.7s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[14:58:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:58:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.987, test=0.876), total=   8.4s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[14:58:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:58:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.984, test=0.851), total=   7.8s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[14:58:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:58:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.985, test=0.859), total=   7.7s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[14:58:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:58:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.988, test=0.861), total=   7.7s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[14:59:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:59:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.988, test=0.865), total=   8.9s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[14:59:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:59:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.985, test=0.848), total=   7.8s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[14:59:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:59:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.985, test=0.868), total=   7.9s\n",
      "[CV] max_depth=10, min_samples_split=500 .............................\n",
      "[14:59:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:59:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=10, min_samples_split=500, score=(train=0.991, test=0.849), total=   8.1s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[14:59:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:59:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=1.000, test=0.876), total=  16.8s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[14:59:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:59:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=1.000, test=0.848), total=  16.3s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[15:00:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:00:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=1.000, test=0.863), total=  15.8s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[15:00:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:00:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=1.000, test=0.854), total=  16.2s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[15:00:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:00:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=1.000, test=0.856), total=  16.3s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[15:00:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:00:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=1.000, test=0.861), total=  15.8s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[15:01:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:01:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=1.000, test=0.852), total=  16.0s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[15:01:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:01:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=1.000, test=0.848), total=  15.8s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[15:01:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:01:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=1.000, test=0.869), total=  16.3s\n",
      "[CV] max_depth=50, min_samples_split=5 ...............................\n",
      "[15:02:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:02:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=5, score=(train=1.000, test=0.849), total=  15.6s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[15:02:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:02:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=1.000, test=0.876), total=  16.3s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[15:02:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:02:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=1.000, test=0.848), total=  15.9s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[15:02:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:02:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=1.000, test=0.863), total=  15.8s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[15:03:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:03:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=1.000, test=0.854), total=  15.8s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[15:03:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:03:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=1.000, test=0.856), total=  16.0s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[15:03:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:03:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=1.000, test=0.861), total=  15.5s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[15:03:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:03:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=1.000, test=0.852), total=  16.2s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[15:04:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:04:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=1.000, test=0.848), total=  15.8s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[15:04:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:04:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=1.000, test=0.869), total=  16.0s\n",
      "[CV] max_depth=50, min_samples_split=10 ..............................\n",
      "[15:04:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:04:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=10, score=(train=1.000, test=0.849), total=  15.5s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[15:05:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:05:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=1.000, test=0.876), total=  16.6s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[15:05:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:05:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=1.000, test=0.848), total=  16.0s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[15:05:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:05:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=1.000, test=0.863), total=  15.4s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[15:05:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:05:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=1.000, test=0.854), total=  15.8s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[15:06:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:06:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=1.000, test=0.856), total=  16.3s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[15:06:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:06:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=1.000, test=0.861), total=  15.8s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[15:06:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:06:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=1.000, test=0.852), total=  15.7s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[15:06:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:06:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=1.000, test=0.848), total=  15.7s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[15:07:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:07:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=1.000, test=0.869), total=  16.3s\n",
      "[CV] max_depth=50, min_samples_split=100 .............................\n",
      "[15:07:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:07:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=100, score=(train=1.000, test=0.849), total=  15.8s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[15:07:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:07:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=1.000, test=0.876), total=  16.1s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[15:08:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:08:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=1.000, test=0.848), total=  15.8s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[15:08:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:08:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=1.000, test=0.863), total=  15.8s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[15:08:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:08:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=1.000, test=0.854), total=  15.7s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[15:08:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:08:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=1.000, test=0.856), total=  15.8s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[15:09:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:09:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=1.000, test=0.861), total=  15.6s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[15:09:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:09:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=1.000, test=0.852), total=  16.1s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[15:09:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:09:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=1.000, test=0.848), total=  15.7s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[15:09:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:09:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=1.000, test=0.869), total=  15.8s\n",
      "[CV] max_depth=50, min_samples_split=500 .............................\n",
      "[15:10:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:10:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  max_depth=50, min_samples_split=500, score=(train=1.000, test=0.849), total=  15.5s\n",
      "[15:10:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:10:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed: 19.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST DEPTH:  10 BEST min_samples_split:  5  BEST SCORE:  0.8613492334500024\n"
     ]
    }
   ],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "clf_xgb2 = GridSearchCV(xgb, parameters, cv= 10, scoring='accuracy', verbose=10,return_train_score=True)\n",
    "clf_xgb2.fit(X_train,y_train)\n",
    "train_score= clf_xgb2.cv_results_['mean_train_score']\n",
    "train_score= clf_xgb2.cv_results_['std_train_score']\n",
    "cv_score = clf_xgb2.cv_results_['mean_test_score']\n",
    "cv_score = clf_xgb2.cv_results_['std_test_score']\n",
    "bestDepth=clf_xgb2.best_params_['max_depth']\n",
    "bestScore=clf_xgb2.best_score_\n",
    "print(\"BEST DEPTH: \",clf_xgb2.best_params_['max_depth'],\"BEST min_samples_split: \",clf_xgb2.best_params_['min_samples_split'],\" BEST SCORE: \",clf_xgb2.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.8450515002239141\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.85      1164\n",
      "           1       0.82      0.87      0.84      1069\n",
      "\n",
      "    accuracy                           0.85      2233\n",
      "   macro avg       0.85      0.85      0.85      2233\n",
      "weighted avg       0.85      0.85      0.85      2233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"score\",clf_xgb2.score(X_test,y_test))\n",
    "print(metrics.classification_report(y_test, clf_xgb2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2260b8aa848>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/44511636/matplotlib-plot-feature-importance-with-feature-names\n",
    "# clf_rf.best_estimator_.feature_importances_\n",
    "feat_importances = pd.Series(clf_rf.best_estimator_.feature_importances_, index=X_train.columns)\n",
    "feat_importances.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
